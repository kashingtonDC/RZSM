{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/aakash/anaconda3/envs/gis/lib/python3.6/site-packages')\n",
    "sys.path.append('/Users/aakash/anaconda3/lib/python3.6/site-packages')\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ee\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18,16]\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in contents:\n",
    "        if line[0:1] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            data.append(line)\n",
    "\n",
    "    headers = [x.replace(\"Soil Moisture Percent\",\"smp\").replace(\" \",\"_\") for x in data[0].split(\",\")]\n",
    "    cols = [x.strip(\"\\n\").split(\",\") for x in data[1:]]\n",
    "\n",
    "    df = pd.DataFrame(cols, columns = headers)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_site_lat_lons(site_num, stations_csv):\n",
    "    df = pd.read_csv(stations_csv)\n",
    "    site = df[df['site_name'].str.contains(site_no)]\n",
    "    \n",
    "    lat, lon = site['lat'].values, site['lon'].values\n",
    "    return lat[0], lon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE --> Numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_from_latlon(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"VV\")).getInfo()))\n",
    "    lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "    lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def make_np_array(data, lats, lons):\n",
    "    # get data from df as arrays\n",
    "    lons = np.array(lons)\n",
    "    lats = np.array(lats)\n",
    "    data = np.array(data) # Set var here \n",
    "                                              \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32)\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] # we start from lower left corner\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def get_ims_dates(ims_list):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = 10 # len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (1, num_images):\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon))\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "    \n",
    "    times = []\n",
    "    for i in imdates:\n",
    "        time_idx = i.find(\"T0\")\n",
    "        ymd = i[time_idx-8:time_idx]\n",
    "        hms = i[time_idx+1:time_idx+7]\n",
    "        times.append(datetime.strptime(ymd+hms, '%Y%m%d%H%M%S'))\n",
    "\n",
    "    return imlist, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = glob.glob(\"*.csv\")\n",
    "txts = glob.glob(\"*.txt\")\n",
    "site_file = txts[0]\n",
    "stations_csv = csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_no = ''.join(c for c in site_file if c.isdigit())\n",
    "data = read_file(site_file)\n",
    "lat, lon = get_site_lat_lons(site_no,stations_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ee Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = ee.Geometry.Point([lon, lat])\n",
    "area = pt.buffer(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the RS products to be queried, sort from oldest im first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = ee.ImageCollection('COPERNICUS/S1_GRD').filterBounds(pt).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).select('VV')\n",
    "col = collection.filterDate('2014-10-03','2018-10-03')\n",
    "t = col.sort('system:time_start')\n",
    "ims = t.toList(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ims and sort out the dates to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1dat, dates = get_ims_dates(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] =  pd.to_datetime(data['Date'], format='%Y%m%d %H:%M')\n",
    "data.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round each startdate to the nearest hour, grab the data that matches that hour \n",
    "rzsm = []\n",
    "ssm = []\n",
    "\n",
    "for i in dates:\n",
    "    start = i.replace(second=0, microsecond=0, minute=0, hour=i.hour)+timedelta(hours=i.minute//30)\n",
    "    df = pd.DataFrame(data.loc[start]).T.astype(np.float)\n",
    "    rzsm.append(df[df.columns[-1]].values)\n",
    "    ssm.append(df[df.columns[-3]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in s1dat:\n",
    "    ssm_mat = np.ones(i.shape)\n",
    "    rzsm_mat = np.ones(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootmats= []\n",
    "surfmats= []\n",
    "\n",
    "for i in rzsm:\n",
    "    rootmats.append(rzsm_mat*i)\n",
    "for i in ssm:\n",
    "    surfmats.append(ssm*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_ssm = [x.flatten() for x in surfmats]\n",
    "flat_rzsm = [x.flatten() for x in rootmats]\n",
    "flat_s1 = [x.flatten() for x in s1dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(flat_s1, flat_rzsm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sigmas = []\n",
    "\n",
    "for i in s1dat:\n",
    "    mean_sigmas.append(np.mean(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mean_sigmas, rzsm, label = 'rzsm')\n",
    "plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data.index,data[data.columns[-1]], label = \"RZ\")\n",
    "plt.scatter(data.index,data[data.columns[-3]], label = \"SSM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
