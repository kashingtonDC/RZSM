{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import ee\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rsfuncs as rs\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18,16]\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE functions are in the rsfuncs module. Loacal functions are here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sm_file(filename):\n",
    "    with open(filename) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in contents:\n",
    "        if line[0:1] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            data.append(line)\n",
    "\n",
    "    headers = [x.replace(\"Soil Moisture Percent\",\"smp\").replace(\" \",\"_\") for x in data[0].split(\",\")]\n",
    "    cols = [x.strip(\"\\n\").split(\",\") for x in data[1:]]\n",
    "\n",
    "    df = pd.DataFrame(cols, columns = headers)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_ims_by_date(ims_list, var, res=10):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (0, num_images):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_images)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon, var, res))\n",
    "        date =  latlon.get('system:time_start')\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "\n",
    "    return imlist, imdates\n",
    "\n",
    "def array_from_latlon(latlon_obj, var, res ):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=res)\n",
    "    try:\n",
    "        lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "        lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "        data = np.array((ee.Array(res.get(var)).getInfo()))\n",
    "    except:\n",
    "        data = np.full_like(lats, np.nan,dtype=np.float64)\n",
    "    \n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def make_np_array(data, lats, lons):\n",
    "    # get data from df as arrays\n",
    "    lons = np.array(lons)\n",
    "    lats = np.array(lats)\n",
    "    data = np.array(data) # Set var here \n",
    "                                              \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32)\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] # we start from lower left corner\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "def get_ndvi(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.mean(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"NDVI\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "def round_up_to_odd(f):\n",
    "    f = int(np.ceil(f))\n",
    "    return f + 1 if f % 2 == 0 else f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_file = gp.read_file(\"../shape/scan_sites.shp\")\n",
    "sites = site_file[~site_file['state'].isin([\"AK\", \"HI\", \"PR\", \"VI\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processings site no 2109\n",
      "Cultivated Crops - Areas used for the production of annual crops, such as corn, soybeans, vegetables, tobacco, and cotton, and also perennial woody crops such as orchards and vineyards. Crop vegetation accounts for greater than 20 percent of total vegetation. This class also includes all land being actively tilled.\n",
      "Processing 7 sentinel overapasses\n",
      "0.0 % \n",
      "71.42 % \n",
      "processing PRISM\n",
      "0.0 % \n",
      "71.42 % \n",
      "processing MODIS\n",
      "0.0 % \n",
      "71.42 % \n",
      "Processing Landsat\n",
      "0.0 % \n",
      "6.944 % \n",
      "13.88 % \n",
      "20.83 % \n",
      "27.77 % \n",
      "34.72 % \n",
      "41.66 % \n",
      "48.61 % \n",
      "55.55 % \n",
      "62.5 % \n",
      "69.44 % \n",
      "76.38 % \n",
      "83.33 % \n",
      "90.27 % \n",
      "97.22 % \n",
      "                       sigma std_sigma precip  LAI  rzsm   psi_rz    ssm  \\\n",
      "date                                                                       \n",
      "2016-01-28 12:05:00 -9.27878   4.16738    0.0  0.3  5.84  21111.7  34.84   \n",
      "2016-01-28 12:05:00 -9.44712   4.25165    0.0  0.3  5.84  21111.7  34.84   \n",
      "2016-02-09 12:05:00 -15.2926   6.87473    0.0  0.2  5.62  26617.5  33.88   \n",
      "\n",
      "                        psi_s lc_type        B1       B4        B5   B1_filt  \\\n",
      "date                                                                           \n",
      "2016-01-28 12:05:00  0.439856      17  0.041574  0.09028  0.154169  0.045377   \n",
      "2016-01-28 12:05:00  0.439856      17  0.041574  0.09028  0.154169  0.045377   \n",
      "2016-02-09 12:05:00  0.520648      17  0.044141  0.09816  0.170492  0.046747   \n",
      "\n",
      "                      B4_filt   B5_filt  \n",
      "date                                     \n",
      "2016-01-28 12:05:00  0.093423  0.152851  \n",
      "2016-01-28 12:05:00  0.093423  0.152851  \n",
      "2016-02-09 12:05:00  0.101778  0.165200  \n",
      "Processings site no 2070\n",
      "Cultivated Crops - Areas used for the production of annual crops, such as corn, soybeans, vegetables, tobacco, and cotton, and also perennial woody crops such as orchards and vineyards. Crop vegetation accounts for greater than 20 percent of total vegetation. This class also includes all land being actively tilled.\n",
      "Processing 7 sentinel overapasses\n",
      "0.0 % \n",
      "71.42 % \n",
      "processing PRISM\n",
      "0.0 % \n",
      "71.42 % \n",
      "processing MODIS\n",
      "0.0 % \n",
      "71.42 % \n",
      "Processing Landsat\n",
      "0.0 % \n",
      "6.944 % \n",
      "13.88 % \n",
      "20.83 % \n",
      "27.77 % \n",
      "34.72 % \n",
      "41.66 % \n",
      "48.61 % \n",
      "55.55 % \n",
      "62.5 % \n",
      "69.44 % \n",
      "76.38 % \n",
      "83.33 % \n",
      "90.27 % \n",
      "97.22 % \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/gis/lib/python3.6/site-packages/ipykernel_launcher.py:180: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sigma std_sigma precip  LAI   rzsm     psi_rz  ssm  \\\n",
      "date                                                                        \n",
      "2016-01-16 12:05:00 -8.34334   3.97983    0.0  0.3  45.36  0.0894786  NaN   \n",
      "2016-01-28 12:05:00  -8.0036   3.63134    0.0  0.3   47.1  0.0712949  NaN   \n",
      "2016-01-28 12:05:00 -7.99326   3.62116    0.0  0.3   47.1  0.0712949  NaN   \n",
      "2016-02-09 12:05:00 -8.42221   3.91675    0.0  0.3   43.5   0.115202  NaN   \n",
      "\n",
      "                    psi_s lc_type        B1        B4        B5   B1_filt  \\\n",
      "date                                                                        \n",
      "2016-01-16 12:05:00   NaN      17  0.045422  0.115011  0.211278  0.044519   \n",
      "2016-01-28 12:05:00   NaN      17  0.045422  0.115011  0.211278  0.044519   \n",
      "2016-01-28 12:05:00   NaN      17  0.045422  0.115011  0.211278  0.044519   \n",
      "2016-02-09 12:05:00   NaN      17  0.045200  0.114000  0.223000  0.054025   \n",
      "\n",
      "                      B4_filt   B5_filt  \n",
      "date                                     \n",
      "2016-01-16 12:05:00  0.113726  0.202455  \n",
      "2016-01-28 12:05:00  0.113726  0.202455  \n",
      "2016-01-28 12:05:00  0.113726  0.202455  \n",
      "2016-02-09 12:05:00  0.130893  0.227344  \n",
      "Processings site no 2086\n",
      "Developed, Open Space - Includes areas with a mixture of some constructed materials, but mostly vegetation in the form of lawn grasses.  Impervious surfaces account for less than 20 percent of total cover. These areas most commonly include large-lot single-family housing units, parks, golf courses, and vegetation planted in developed settings for recreation, erosion control, or aesthetic purposes.\n",
      "Processing 9 sentinel overapasses\n",
      "0.0 % \n",
      "55.55 % \n",
      "processing PRISM\n",
      "0.0 % \n",
      "55.55 % \n",
      "processing MODIS\n",
      "0.0 % \n",
      "55.55 % \n",
      "Processing Landsat\n",
      "0.0 % \n",
      "6.944 % \n",
      "13.88 % \n",
      "20.83 % \n",
      "27.77 % \n",
      "34.72 % \n",
      "41.66 % \n",
      "48.61 % \n",
      "55.55 % \n"
     ]
    }
   ],
   "source": [
    "# For each site id, find the sm file with the data (in data dir), \n",
    "# calculate psi as psi = A * SM ^b (krishna's paper )\n",
    "# query the (1) landcover, (2) Sentinel backscatter (Prism P), MODIS / Landsat LAI for the whole timeseries \n",
    "   \n",
    "for idx, row in sites[81:].iterrows():\n",
    "    \n",
    "    print(\"Processings site no {}\".format(row.id))\n",
    "    \n",
    "    # Make geom to submit to EE \n",
    "    x,y = row.geometry.buffer(0.0001).envelope.exterior.coords.xy\n",
    "    coords = [list(zip(x,y))]\n",
    "    area = ee.Geometry.Polygon(coords)\n",
    "    \n",
    "    # Get the corresponding SCAN data file from data folder\n",
    "    site_id = row.id\n",
    "    sm_file = [os.path.join(data_dir,x) for x in os.listdir(data_dir) if site_id in x][0]\n",
    "    sm_dat = read_sm_file(sm_file)\n",
    "    sm_dat['Date'] =  pd.to_datetime(sm_dat['Date'], format='%Y%m%d %H:%M')\n",
    "    sm_dat.set_index('Date', inplace=True)\n",
    "        \n",
    "    # start and end date\n",
    "    startdate = sm_dat.index[0]\n",
    "    enddate = sm_dat.index[-1]\n",
    "    \n",
    "    date = startdate.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    # Select the nlcd dataset\n",
    "    dataset =  rs.load_data()['nlcd']\n",
    "    ic = dataset[0]\n",
    "    var = dataset[1]\n",
    "    res = dataset[3]\n",
    "    \n",
    "    # find the nearest nlcd dataset \n",
    "    col = ic.filterDate(ee.Date(date).advance(-1, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    if not col.getInfo():\n",
    "        col = ic.filterDate(ee.Date(date).advance(-3, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    t = col.reduceRegion(ee.Reducer.frequencyHistogram(), area, res).get(var)\n",
    "    meta = col.getInfo()\n",
    "    lc_class = int(list(t.getInfo().keys())[0])\n",
    "    \n",
    "    # Get the landcover type\n",
    "    lcidx = meta['properties']['landcover_class_values'].index(lc_class)\n",
    "    lctype = meta['properties']['landcover_class_names'][lcidx]\n",
    "    print(lctype)\n",
    "    lctypes.append(lctype)\n",
    "    \n",
    "    # Get Sentinel images and dates (ascending orbits only, VV polarization)\n",
    "    s1 = rs.load_data()['s1']\n",
    "    s1ic, s1var, s1res = s1[0], s1[1], s1[3]\n",
    "    \n",
    "    s1_col = s1ic.filterBounds(area).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "    s1_col = s1_col.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).select(s1var)\n",
    "    \n",
    "    # Krishna used ascending pass... I think descending is the correct orbit for the AM \n",
    "    \n",
    "    s1_col = s1_col.filterDate(startdate,enddate)\n",
    "    t = s1_col.sort('system:time_start')\n",
    "    \n",
    "    try:\n",
    "        ims = t.toList(t.size())\n",
    "        print(\"Processing {} sentinel overapasses\".format(len(ims.getInfo())))\n",
    "        s1dat, dates = get_ims_by_date(ims,s1var)\n",
    "        \n",
    "    except:\n",
    "        print(\"no valid overpasses\")\n",
    "        continue\n",
    "    \n",
    "    # Calc the S1 backscatter in each image\n",
    "    mean_sigmas = []\n",
    "    std_sigmas = []\n",
    "\n",
    "    for i in s1dat:\n",
    "        mean_sigmas.append(np.mean(i))\n",
    "        std_sigmas.append(np.std(i))\n",
    "        \n",
    "    # Convert the datestrings from S1 to pandas datetimes \n",
    "    for idx, x in enumerate(dates):\n",
    "        timestamp = x.find(\"V_\")+2\n",
    "        timestr = x[timestamp:timestamp+13]\n",
    "        dates[idx] = pd.to_datetime(timestr, format='%Y%m%d %H:%M')\n",
    "        \n",
    "    # Get PRISM data for all the S1 overpass dates to filter the rainy days\n",
    "    print(\"processing PRISM\")\n",
    "    rainfall = []\n",
    "\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "        \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "        t = filter_date(rs.load_data()['prism_daily'][0], y, m, d).sum()\n",
    "        precip_total = get_2day_precip(t, area)\n",
    "        rainfall.append(precip_total)\n",
    "\n",
    "    \n",
    "    # MODIS LAI \n",
    "    print(\"processing MODIS\")\n",
    "    modis = rs.load_data()['modis_lai']\n",
    "    mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "    modis_lai = []\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "            \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "        start = ee.Date.fromYMD(y,m,d).advance(-2,\"day\")\n",
    "        end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "        prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()\n",
    "\n",
    "        try:\n",
    "            res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=5) # Need to have scale smaller than geom\n",
    "            data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "            out = np.array(data)* 0.1\n",
    "            modis_lai.append(out)\n",
    "        except:\n",
    "            out = np.nan\n",
    "            modis_lai.append(np.nan)\n",
    "            \n",
    "    # Landsat - Note: some sites are in the overlap areas between passes.\n",
    "    # these sites can have multiple obs / day or obs separated by 8days instead of 16. \n",
    "    \n",
    "    print(\"Processing Landsat\")\n",
    "    landsat = rs.load_data()['l8_sr']\n",
    "    lic, lvar, lsf = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "    lstart = ee.Date.fromYMD(startdate.year,startdate.month,startdate.day).advance(-16,\"day\")\n",
    "    lend = ee.Date.fromYMD(enddate.year,enddate.month,enddate.day).advance(16, \"day\")\n",
    "\n",
    "    l8_col = lic.filterDate(lstart,lend).filterBounds(area).map(rs.mask_quality) # Mask clouds and shadows \n",
    "    lt = l8_col.sort('system:time_start')\n",
    "    lims = lt.toList(lt.size())\n",
    "\n",
    "    num_ims = len(lims.getInfo())\n",
    "\n",
    "    ldfs = []\n",
    "\n",
    "    for i in range (0, num_ims):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "        ls_latlon = ee.Image.pixelLonLat().addBands(lims.get(i))\n",
    "        ltemp = ls_latlon.select([\"B1\", \"B4\", \"B5\"]).multiply(lsf)\n",
    "        l8_res = ltemp.reduceRegion(reducer=ee.Reducer.mean(),geometry=area,bestEffort=True,scale=30)\n",
    "\n",
    "        l8_info_dict = lims.get(i).getInfo()\n",
    "        l8_date = l8_info_dict['id'][-8:]\n",
    "\n",
    "        l8_out = l8_res.getInfo()\n",
    "\n",
    "        ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "        ldf.columns = l8_out.keys()\n",
    "        ldf.index = pd.to_datetime([l8_date])\n",
    "        ldfs.append(ldf)\n",
    "        \n",
    "                        \n",
    "    # Filter the SCAN data for the S1 dates, 3 am - 7 am \n",
    "    rzsm = []\n",
    "    ssm = []\n",
    "    \n",
    "    for i in dates:\n",
    "        starttime = i.replace(second=0, microsecond=0, minute=0, hour=3)\n",
    "        endtime = starttime+timedelta(hours= 4)\n",
    "        df = pd.DataFrame(sm_dat[starttime:endtime])\n",
    "        \n",
    "        rzsm.append(df[df.columns[-1]].values)\n",
    "        ssm.append(df[df.columns[-3]].values)\n",
    "    \n",
    "    # In case there are nans or data gaps in the sm data\n",
    "    rzsm = [list(filter(None, x)) for x in rzsm]\n",
    "    ssm = [list(filter(None, x)) for x in ssm]\n",
    "    \n",
    "    # Calc the 5 hour mean for each sensor reading \n",
    "    for idx,x in enumerate(rzsm):\n",
    "        rzsm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "    \n",
    "    for idx,x in enumerate(ssm):\n",
    "        ssm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "\n",
    "    # params to calculate psi \n",
    "    a = row.a\n",
    "    b = row.b\n",
    "    \n",
    "    # RZ and Surface LWP = A * sm ^b\n",
    "    psi1 = [a*(x/100)**b for x in rzsm]\n",
    "    psi2 = [a*(x/100)**b for x in ssm]\n",
    "    \n",
    "    # Make a dataframe out of everything\n",
    "    df = pd.DataFrame([dates, mean_sigmas, std_sigmas, rainfall, modis_lai, rzsm,psi1,ssm,psi2, [lcidx]*len(dates)])\n",
    "    df = df.T\n",
    "    df.columns = (['date', \"sigma\", \"std_sigma\", \"precip\",\"LAI\", \"rzsm\",\"psi_rz\", \"ssm\", \"psi_s\", \"lc_type\"])\n",
    "    df = rs.col_to_dt(df) # set the date col as datetime index \n",
    "    mask=(df['precip'] < 0.1)\n",
    "    dfout = df[mask]\n",
    "\n",
    "    # For now append the nearest landsat image band values to the master df \n",
    "    # TODO: Golay interpolation \n",
    "    \n",
    "    ls = pd.concat(ldfs)\n",
    "    win_len = round_up_to_odd(num_ims/7)\n",
    "    \n",
    "    for i in ls.columns:\n",
    "        ls[i][ls[i] == 0] = np.nan\n",
    "        ls[i] = ls[i].interpolate(method = \"linear\")\n",
    "        ls[i+\"_filt\"] = savgol_filter(ls[i], window_length=win_len, polyorder=2)\n",
    "    \n",
    "    ls_df = ls[(ls.T != 0).any()]\n",
    "    ls_df = ls_df.groupby(level = 0).mean()\n",
    "    \n",
    "    # Break the loop if there are no non- rainy sentinel overpasses \n",
    "    if dfout.empty:\n",
    "        print(\"No non-rainy overpaasses \")\n",
    "        continue \n",
    "        \n",
    "    l8_dfs = []\n",
    "    \n",
    "    for i in dfout.index:\n",
    "        l8_idx = ls_df.index.get_loc(i, method='nearest')\n",
    "        l8_contemp = ls_df.iloc[l8_idx]\n",
    "        t = pd.DataFrame(l8_contemp).T\n",
    "        l8_dfs.append(t)\n",
    "    \n",
    "    fin_ls = pd.concat(l8_dfs)\n",
    "\n",
    "    FIN = pd.concat( [dfout.reset_index(drop=True), fin_ls.reset_index(drop=True)], axis=1) \n",
    "    FIN.index = dfout.index\n",
    "\n",
    "    print(FIN.head())\n",
    "    \n",
    "    out_dict[(row.id)] = FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t.B4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(mean_sigmas)\n",
    "x = x.reshape(x.shape[0])\n",
    "y = np.array(rzsm)\n",
    "y = y.reshape(y.shape[0])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture \n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], \"10\"))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(mean_sigmas, rzsm, label = 'rzsm')\n",
    "plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"$\\sigma$ (dB)\", color=color)\n",
    "ax1.plot(dates, mean_sigmas, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the days with high preceding rainfall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''2 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"Precip (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test with 4 day precip accumulation\n",
    "\n",
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-4, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])\n",
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])\n",
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''4 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"3 day precipitation (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation (4 days)\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
