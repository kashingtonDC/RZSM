{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import ee\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rsfuncs as rs\n",
    "\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18,16]\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE functions are in the rsfuncs module. Loacal functions are here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sm_file(filename):\n",
    "    with open(filename) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in contents:\n",
    "        if line[0:1] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            data.append(line)\n",
    "\n",
    "    headers = [x.replace(\"Soil Moisture Percent\",\"smp\").replace(\" \",\"_\") for x in data[0].split(\",\")]\n",
    "    cols = [x.strip(\"\\n\").split(\",\") for x in data[1:]]\n",
    "\n",
    "    df = pd.DataFrame(cols, columns = headers)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_ims_by_date(ims_list, var, res=10):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (0, num_images):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_images)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon, var, res))\n",
    "        date =  latlon.get('system:time_start')\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "\n",
    "    return imlist, imdates\n",
    "\n",
    "def array_from_latlon(latlon_obj, var, res ):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=res)\n",
    "    try:\n",
    "        lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "        lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "        data = np.array((ee.Array(res.get(var)).getInfo()))\n",
    "    except:\n",
    "        data = np.full_like(lats, np.nan,dtype=np.float64)\n",
    "    \n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def make_np_array(data, lats, lons):\n",
    "    # get data from df as arrays\n",
    "    lons = np.array(lons)\n",
    "    lats = np.array(lats)\n",
    "    data = np.array(data) # Set var here \n",
    "                                              \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32)\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] # we start from lower left corner\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "def get_ndvi(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.mean(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"NDVI\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_file = gp.read_file(\"../shape/scan_sites.shp\")\n",
    "sites = site_file[~site_file['state'].isin([\"AK\", \"HI\", \"PR\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "lctypes = []\n",
    "ls_dfs = []\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processings site no 2057\n"
     ]
    }
   ],
   "source": [
    "# For each site id, find the sm file with the data (in data dir), \n",
    "# calculate psi as psi = A * SM ^b (krishna's paper )\n",
    "# query the (1) landcover, (2) Sentinel backscatter (Prism P), MODIS / Landsat LAI for the whole timeseries \n",
    "   \n",
    "for idx, row in sites.iterrows():\n",
    "    \n",
    "    print(\"Processings site no {}\".format(row.id))\n",
    "    \n",
    "    # Make geom to submit to EE \n",
    "    x,y = row.geometry.buffer(0.0001).envelope.exterior.coords.xy\n",
    "    coords = [list(zip(x,y))]\n",
    "    area = ee.Geometry.Polygon(coords)\n",
    "    \n",
    "    # Get the corresponding SCAN data file from data folder\n",
    "    site_id = row.id\n",
    "    sm_file = [os.path.join(data_dir,x) for x in os.listdir(data_dir) if site_id in x][0]\n",
    "    sm_dat = read_sm_file(sm_file)\n",
    "    sm_dat['Date'] =  pd.to_datetime(sm_dat['Date'], format='%Y%m%d %H:%M')\n",
    "    sm_dat.set_index('Date', inplace=True)\n",
    "        \n",
    "    # start and end date\n",
    "    startdate = sm_dat.index[0]\n",
    "    enddate = sm_dat.index[-1]\n",
    "    \n",
    "    date = startdate.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    # Select the nlcd dataset\n",
    "    dataset =  rs.load_data()['nlcd']\n",
    "    ic = dataset[0]\n",
    "    var = dataset[1]\n",
    "    res = dataset[3]\n",
    "    \n",
    "    # find the nearest nlcd dataset \n",
    "    col = ic.filterDate(ee.Date(date).advance(-1, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    t = col.reduceRegion(ee.Reducer.frequencyHistogram(), area, res).get(var)\n",
    "    meta = col.getInfo()\n",
    "    lc_class = int(list(t.getInfo().keys())[0])\n",
    "    \n",
    "    # Get the landcover type\n",
    "    lcidx = meta['properties']['landcover_class_values'].index(lc_class)\n",
    "    lctype = meta['properties']['landcover_class_names'][lcidx]\n",
    "    print(lctype)\n",
    "    lctypes.append(lctype)\n",
    "    \n",
    "    # Get Sentinel images and dates (ascending orbits only, VV polarization)\n",
    "    s1 = rs.load_data()['s1']\n",
    "    s1ic, s1var, s1res = s1[0], s1[1], s1[3]\n",
    "    \n",
    "    s1_col = s1ic.filterBounds(area).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "    s1_col = s1_col.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).select(s1var)\n",
    "    \n",
    "    # Krishna used ascending pass... I think descending is the correct orbit for the AM \n",
    "    \n",
    "    s1_col = s1_col.filterDate(startdate,enddate)\n",
    "    t = s1_col.sort('system:time_start')\n",
    "    \n",
    "    try:\n",
    "        ims = t.toList(t.size())\n",
    "        print(\"Processing {} sentinel overapasses\".format(len(ims.getInfo())))\n",
    "        s1dat, dates = get_ims_by_date(ims,s1var)\n",
    "        \n",
    "    except:\n",
    "        print(\"no valid overpasses\")\n",
    "        continue\n",
    "    \n",
    "    # Calc the S1 backscatter in each image\n",
    "    mean_sigmas = []\n",
    "    std_sigmas = []\n",
    "\n",
    "    for i in s1dat:\n",
    "        mean_sigmas.append(np.mean(i))\n",
    "        std_sigmas.append(np.std(i))\n",
    "        \n",
    "    # Convert the datestrings from S1 to pandas datetimes \n",
    "    for idx, x in enumerate(dates):\n",
    "        timestamp = x.find(\"V_\")+2\n",
    "        timestr = x[timestamp:timestamp+13]\n",
    "        dates[idx] = pd.to_datetime(timestr, format='%Y%m%d %H:%M')\n",
    "        \n",
    "    # Get PRISM data for all the S1 overpass dates to filter the rainy days\n",
    "    print(\"processing PRISM\")\n",
    "    rainfall = []\n",
    "\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "        \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "        t = filter_date(rs.load_data()['prism_daily'][0], y, m, d).sum()\n",
    "        precip_total = get_2day_precip(t, area)\n",
    "        rainfall.append(precip_total)\n",
    "\n",
    "    \n",
    "    # MODIS LAI \n",
    "    print(\"processing MODIS\")\n",
    "    modis = rs.load_data()['modis_lai']\n",
    "    mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "    modis_lai = []\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "            \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "        start = ee.Date.fromYMD(y,m,d).advance(-2,\"day\")\n",
    "        end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "        prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()\n",
    "\n",
    "        try:\n",
    "            res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=5) # Need to have scale smaller than geom\n",
    "            data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "            out = np.array(data)* 0.1\n",
    "            modis_lai.append(out)\n",
    "        except:\n",
    "            out = np.nan\n",
    "            modis_lai.append(np.nan)\n",
    "            \n",
    "    # Landsat - Note: some sites are in the overlap areas between passes.\n",
    "    # these sites can have multiple obs / day or obs separated by 8days instead of 16. \n",
    "    \n",
    "    print(\"Processing Landsat\")\n",
    "    landsat = rs.load_data()['l8_sr']\n",
    "    lic, lvar, lsf = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "    lstart = ee.Date.fromYMD(startdate.year,startdate.month,startdate.day).advance(-16,\"day\")\n",
    "    lend = ee.Date.fromYMD(enddate.year,enddate.month,enddate.day).advance(16, \"day\")\n",
    "\n",
    "    l8_col = lic.filterDate(lstart,lend).filterBounds(area).map(rs.mask_quality) # Mask clouds and shadows \n",
    "    lt = l8_col.sort('system:time_start')\n",
    "    lims = lt.toList(lt.size())\n",
    "\n",
    "    num_ims = len(lims.getInfo())\n",
    "\n",
    "    ldfs = []\n",
    "\n",
    "    for i in range (0, num_ims):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "        ls_latlon = ee.Image.pixelLonLat().addBands(lims.get(i))\n",
    "        ltemp = ls_latlon.select([\"B1\", \"B4\", \"B5\"]).multiply(lsf)\n",
    "        l8_res = ltemp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,bestEffort=True,scale=30)\n",
    "\n",
    "        l8_info_dict = lims.get(i).getInfo()\n",
    "        l8_date = l8_info_dict['id'][-8:]\n",
    "\n",
    "        l8_out = l8_res.getInfo()\n",
    "\n",
    "        ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "        ldf.columns = l8_out.keys()\n",
    "        ldf.index = pd.to_datetime([l8_date])\n",
    "        ldfs.append(ldf)\n",
    "        \n",
    "    ls_dfs.append(ldfs)\n",
    "                        \n",
    "    # Filter the SCAN data for the S1 dates, 3 am - 7 am \n",
    "    rzsm = []\n",
    "    ssm = []\n",
    "    \n",
    "    for i in dates:\n",
    "        starttime = i.replace(second=0, microsecond=0, minute=0, hour=3)\n",
    "        endtime = starttime+timedelta(hours= 4)\n",
    "        df = pd.DataFrame(sm_dat[starttime:endtime])\n",
    "        \n",
    "        rzsm.append(df[df.columns[-1]].values)\n",
    "        ssm.append(df[df.columns[-3]].values)\n",
    "    \n",
    "    # In case there are nans or data gaps in the sm data\n",
    "    rzsm = [list(filter(None, x)) for x in rzsm]\n",
    "    ssm = [list(filter(None, x)) for x in ssm]\n",
    "    \n",
    "    # Calc the 5 hour mean for each sensor reading \n",
    "    for idx,x in enumerate(rzsm):\n",
    "        rzsm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "    \n",
    "    for idx,x in enumerate(ssm):\n",
    "        ssm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "\n",
    "    # params to calculate psi \n",
    "    a = row.a\n",
    "    b = row.b\n",
    "    \n",
    "    # RZ and Surface LWP = A * sm ^b\n",
    "    psi1 = [a*(x/100)**b for x in rzsm]\n",
    "    psi2 = [a*(x/100)**b for x in ssm]\n",
    "    \n",
    "    # Make a dataframe out of everything\n",
    "    df = pd.DataFrame([dates, mean_sigmas, std_sigmas, rainfall, modis_lai, rzsm,psi1,ssm,psi2])\n",
    "    df = df.T\n",
    "    df.columns = (['date', \"sigma\", \"std_sigma\", \"precip\",\"LAI\", \"rzsm\",\"psi_rz\", \"ssm\", \"psi_s\"])\n",
    "    df = rs.col_to_dt(df) # set the date col as datetime index \n",
    "    mask=(df['precip'] < 0.1)\n",
    "    dfout = df[mask]\n",
    "    \n",
    "    # For now append the nearest landsat image band values to the master df \n",
    "    # TODO: Golay interpolation \n",
    "    \n",
    "    ls = pd.concat(ldfs)\n",
    "    ls_df = ls[(ls.T != 0).any()]\n",
    "\n",
    "    for i in dfout.index:\n",
    "        ls_df.reset_index().pivot_table(columns=[\"index\"]).T\n",
    "        ls_df[ls_df.index.duplicated(keep = 'last')]\n",
    "        l8_idx = ls_df.index.get_loc(i, method='nearest')\n",
    "        l8_contemp = ls_df.iloc[l8_idx]\n",
    "        t = pd.DataFrame(l8_contemp).T\n",
    "\n",
    "    FIN = pd.concat( [dfout.reset_index(drop=True), t.reset_index(drop=True)], axis=1) \n",
    "    FIN.index = dfout.index\n",
    "    \n",
    "    print(FIN.head())\n",
    "    \n",
    "    results.append(FIN)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>0.1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.1457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-24</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>0.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-30</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-17</th>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.3562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-17</th>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.3554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-19</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-19</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-04</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-04</th>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.2519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-05</th>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-05</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-07</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.2858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-07</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-23</th>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-23</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.2876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-10</th>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-10</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.1593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-28</th>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-28</th>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.1704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-03</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.2524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-03</th>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>0.2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-21</th>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>0.3255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-21</th>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.3261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-06</th>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-06</th>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.2903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-23</th>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.3038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-23</th>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.3043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09</th>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-09</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-25</th>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.2527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-25</th>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-10</th>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-10</th>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-26</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.1677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-13</th>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.1809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-13</th>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-29</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-29</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-02</th>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.1809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-02</th>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-24</th>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-24</th>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.2974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.3511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.3502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-26</th>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.2892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-26</th>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.2903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-12</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>0.2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-12</th>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.2610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.2321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                B1      B4      B5\n",
       "2015-01-08  0.0377  0.0917  0.1451\n",
       "2015-01-08  0.0368  0.0916  0.1457\n",
       "2015-01-24  0.0215  0.0794  0.1375\n",
       "2015-01-24  0.0223  0.0791  0.1380\n",
       "2015-04-30  0.0625  0.1254  0.2878\n",
       "2015-06-17  0.0314  0.0497  0.3562\n",
       "2015-06-17  0.0314  0.0501  0.3554\n",
       "2015-07-19  0.0219  0.0511  0.3157\n",
       "2015-07-19  0.0211  0.0508  0.3157\n",
       "2015-08-04  0.0368  0.0582  0.2497\n",
       "2015-08-04  0.0364  0.0584  0.2519\n",
       "2015-09-05  0.0466  0.1022  0.2488\n",
       "2015-09-05  0.0447  0.1030  0.2507\n",
       "2015-10-07  0.0428  0.0999  0.2858\n",
       "2015-10-07  0.0416  0.0993  0.2861\n",
       "2015-10-23  0.0414  0.0954  0.2867\n",
       "2015-10-23  0.0418  0.0944  0.2876\n",
       "2015-12-10  0.0174  0.0551  0.1018\n",
       "2015-12-10  0.0323  0.0587  0.1006\n",
       "2016-01-11  0.0403  0.0919  0.1600\n",
       "2016-01-11  0.0408  0.0916  0.1593\n",
       "2016-02-28  0.0474  0.1016  0.1699\n",
       "2016-02-28  0.0467  0.1014  0.1704\n",
       "2016-03-15  0.0485  0.1082  0.1945\n",
       "2016-03-15  0.0470  0.1073  0.1942\n",
       "2016-06-03  0.0428  0.0938  0.2524\n",
       "2016-06-03  0.0420  0.0957  0.2554\n",
       "2016-07-21  0.0326  0.1093  0.3255\n",
       "2016-07-21  0.0327  0.1104  0.3261\n",
       "2016-08-06  0.0324  0.0696  0.3101\n",
       "2016-08-06  0.0343  0.0697  0.3099\n",
       "2016-09-07  0.0357  0.0588  0.2908\n",
       "2016-09-07  0.0350  0.0587  0.2903\n",
       "2016-09-23  0.0616  0.1371  0.3038\n",
       "2016-09-23  0.0613  0.1372  0.3043\n",
       "2016-10-09  0.0451  0.1338  0.2716\n",
       "2016-10-09  0.0447  0.1346  0.2728\n",
       "2016-10-25  0.0489  0.1268  0.2527\n",
       "2016-10-25  0.0489  0.1276  0.2543\n",
       "2016-11-10  0.0497  0.1297  0.2566\n",
       "2016-11-10  0.0505  0.1313  0.2580\n",
       "2016-11-26  0.0247  0.0909  0.1677\n",
       "2017-01-13  0.0471  0.1088  0.1809\n",
       "2017-01-13  0.0497  0.1097  0.1814\n",
       "2017-01-29  0.0421  0.0972  0.1656\n",
       "2017-01-29  0.0424  0.0970  0.1661\n",
       "2017-03-02  0.0352  0.0927  0.1809\n",
       "2017-03-02  0.0347  0.0922  0.1813\n",
       "2017-07-24  0.0551  0.1269  0.2965\n",
       "2017-07-24  0.0537  0.1220  0.2974\n",
       "2017-08-25  0.0277  0.0704  0.3511\n",
       "2017-08-25  0.0273  0.0700  0.3502\n",
       "2017-09-26  0.0284  0.0530  0.2892\n",
       "2017-09-26  0.0279  0.0529  0.2903\n",
       "2017-10-12  0.0263  0.0517  0.2620\n",
       "2017-10-12  0.0301  0.0525  0.2610\n",
       "2017-11-13  0.0024  0.0569  0.2324\n",
       "2017-11-13  0.0132  0.0603  0.2321"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dfout.index:\n",
    "    l8_idx = ls_df.index.get_loc(i, method='nearest')\n",
    "    l8_contemp = ls_df.iloc[l8_idx]\n",
    "    t = pd.DataFrame(l8_contemp).T\n",
    "    t.reset_index(drop=True, inplace=True)\n",
    "    dfout[t.columns] = t.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = pd.concat( [dfout.reset_index(drop=True), t.reset_index(drop=True)], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf.index = dfout.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = ls[(ls.T != 0).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = pd.concat(ls_dfs[1])\n",
    "df2 = ls[(ls.T != 0).any()]\n",
    "\n",
    "df = rs.col_to_dt(df)\n",
    "ls_df = ls[(ls.T != 0).any()]\n",
    "\n",
    "for i in df.index:\n",
    "    l8_idx = df2.index.get_loc(i, method='nearest')\n",
    "    l8_contemp = df2.iloc[l8_idx]\n",
    "    t = pd.DataFrame(l8_contemp).T\n",
    "    t.reset_index(drop=True, inplace=True)\n",
    "    df[t.columns] = t.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[t.columns] = t.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = sm_dat.index[0]\n",
    "enddate = sm_dat.index[-1]\n",
    "    \n",
    "\n",
    "landsat = rs.load_data()['l8_sr']\n",
    "lic, lvar, lsf = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "lstart = ee.Date.fromYMD(startdate.year,startdate.month,startdate.day).advance(-16,\"day\")\n",
    "lend = ee.Date.fromYMD(enddate.year,enddate.month,enddate.day).advance(16, \"day\")\n",
    "\n",
    "l8_col = lic.filterDate(lstart,lend).filterBounds(area).map(rs.mask_quality)\n",
    "lt = l8_col.sort('system:time_start')\n",
    "lims = lt.toList(lt.size())\n",
    "\n",
    "num_ims = len(lims.getInfo())\n",
    "\n",
    "ldfs = []\n",
    "\n",
    "for i in range (0, num_ims):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "    ls_latlon = ee.Image.pixelLonLat().addBands(lims.get(i))\n",
    "    ltemp = ls_latlon.select([\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"]).multiply(lsf)\n",
    "    l8_res = ltemp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=30)\n",
    "\n",
    "    l8_info_dict = lims.get(i).getInfo()\n",
    "    l8_date = l8_info_dict['id'][-8:]\n",
    "\n",
    "    l8_out = l8_res.getInfo()\n",
    "\n",
    "    ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "    ldf.columns = l8_out.keys()\n",
    "    ldf.index = pd.to_datetime([l8_date])\n",
    "    ldfs.append(ldf)\n",
    "    print(ldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(2).getInfo()['properties']['system:index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(3).getInfo()['properties']['system:index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(10).getInfo()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(11).getInfo()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(0).getInfo()['properties']['system:index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()\n",
    "landsat = data['l8_sr']\n",
    "lic, lvar, lsf = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "start = ee.Date.fromYMD(startdate.year,startdate.month,startdate.day).advance(8,\"day\")\n",
    "end = ee.Date.fromYMD(enddate.year,enddate.month,enddate.day).advance(8, \"day\")\n",
    "\n",
    "l8_col = lic.filterDate(start,end).filterBounds(area).map(rs.mask_quality)\n",
    "t = l8_col.sort('system:time_start')\n",
    "ims = t.toList(t.size())\n",
    "\n",
    "num_ims = len(ims.getInfo())\n",
    "\n",
    "ldfs = []\n",
    "\n",
    "for i in range (0, num_ims):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "    latlon = ee.Image.pixelLonLat().addBands(ims.get(i))\n",
    "    temp = latlon.select([\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"]).multiply(lsf)\n",
    "    res = temp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,scale=30)\n",
    "    info_dict = lims.get(i).getInfo()\n",
    "    l8_date = info_dict['id'][-8:]\n",
    "\n",
    "    l8_out = res.getInfo()\n",
    "\n",
    "    ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "    ldf.columns = l8_out.keys()\n",
    "    ldf.index = pd.to_datetime([l8_date])\n",
    "    ldfs.append(ldf)\n",
    "    \n",
    "    print(ldf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_out = res.getInfo()\n",
    "\n",
    "ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "ldf.columns = l8_out.keys()\n",
    "ldf.index = pd.to_datetime([l8_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_d1.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()\n",
    "\n",
    "landsat = data['l8_sr']\n",
    "lic, lvar, lres = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "sd = \n",
    "\n",
    "l8_col = lic.filterDate(ee.Date(startdate).advance(\"day\", -16),ee.Date(enddate).advance(\"day\", 16)).filterBounds(area)\n",
    "t = l8_col.sort('system:time_start')\n",
    "ims = t.toList(t.size())\n",
    "\n",
    "num_ims = len(ims.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlist = []\n",
    "\n",
    "for i in range (0, num_ims):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims.get(i))\n",
    "        temp = latlon.select([\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"]).getInfo()\n",
    "        res = temp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=30)\n",
    "\n",
    "        \n",
    "#         imlist.append(array_from_latlon(latlon, \"B7\", 30))\n",
    "#         date =  latlon.get('system:time_start')\n",
    "#         info_dict = ims.get(i).getInfo()\n",
    "#         date = info_dict['id']\n",
    "#         imdates.append(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = latlon.select([\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = temp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (0, num_images):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_images)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon, var, res))\n",
    "        date =  latlon.get('system:time_start')\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "\n",
    "    return imlist, imdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat = data['l8_sr']\n",
    "lic, lvar, lres = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "for i,x in enumerate(dates[:1]):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    \n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-8,\"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d).advance(8, \"day\")\n",
    "\n",
    "    prod = lic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()\n",
    "    l8_im= prod.filterBounds(area).map(rs.mask_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    s1_col = s1_col.filterDate(startdate,enddate)\n",
    "    t = s1_col.sort('system:time_start')\n",
    "    \n",
    "    try:\n",
    "        ims = t.toList(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    band_name = col.select(band).median()\n",
    "    latlon = ee.Image.pixelLonLat().addBands(band_name).multiply(0.0001)\n",
    "\n",
    "    # apply reducer to list\n",
    "    latlon = latlon.reduceRegion(\n",
    "      reducer=ee.Reducer.toList(),\n",
    "      geometry=bounds,\n",
    "      maxPixels=1e13,\n",
    "      scale=res)\n",
    "    \n",
    "    data = np.array((ee.Array(latlon.get(band)).getInfo()))\n",
    "    lats = np.array((ee.Array(latlon.get(\"latitude\")).getInfo()))\n",
    "    lons = np.array((ee.Array(latlon.get(\"longitude\")).getInfo()))\n",
    "    \n",
    "    arr = array_from_coords(data,lats,lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-2,\"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "    prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(mean_sigmas)\n",
    "x = x.reshape(x.shape[0])\n",
    "y = np.array(rzsm)\n",
    "y = y.reshape(y.shape[0])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture \n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], \"10\"))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(mean_sigmas, rzsm, label = 'rzsm')\n",
    "plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"$\\sigma$ (dB)\", color=color)\n",
    "ax1.plot(dates, mean_sigmas, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the days with high preceding rainfall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''2 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"Precip (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test with 4 day precip accumulation\n",
    "\n",
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-4, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])\n",
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])\n",
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''4 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"3 day precipitation (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation (4 days)\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py 3 gis",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
