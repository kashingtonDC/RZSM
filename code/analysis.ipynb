{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import ee\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rsfuncs as rs\n",
    "\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18,16]\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE functions are in the rsfuncs module. Loacal functions are here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sm_file(filename):\n",
    "    with open(filename) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in contents:\n",
    "        if line[0:1] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            data.append(line)\n",
    "\n",
    "    headers = [x.replace(\"Soil Moisture Percent\",\"smp\").replace(\" \",\"_\") for x in data[0].split(\",\")]\n",
    "    cols = [x.strip(\"\\n\").split(\",\") for x in data[1:]]\n",
    "\n",
    "    df = pd.DataFrame(cols, columns = headers)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_ims_by_date(ims_list, var, res=10):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (0, num_images):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_images)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon, var, res))\n",
    "        date =  latlon.get('system:time_start')\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "\n",
    "    return imlist, imdates\n",
    "\n",
    "def array_from_latlon(latlon_obj, var, res ):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=res)\n",
    "    try:\n",
    "        lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "        lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "        data = np.array((ee.Array(res.get(var)).getInfo()))\n",
    "    except:\n",
    "        data = np.full_like(lats, np.nan,dtype=np.float64)\n",
    "    \n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def make_np_array(data, lats, lons):\n",
    "    # get data from df as arrays\n",
    "    lons = np.array(lons)\n",
    "    lats = np.array(lats)\n",
    "    data = np.array(data) # Set var here \n",
    "                                              \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32)\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] # we start from lower left corner\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "def get_ndvi(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.mean(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"NDVI\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_file = gp.read_file(\"../shape/scan_sites.shp\")\n",
    "sites = site_file[~site_file['state'].isin([\"AK\", \"HI\", \"PR\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processings site no 2057\n"
     ]
    }
   ],
   "source": [
    "# For each site id, find the sm file with the data (in data dir), \n",
    "# calculate psi as psi = A * SM ^b (krishna's paper )\n",
    "# query the (1) landcover, (2) Sentinel backscatter (Prism P), MODIS / Landsat LAI for the whole timeseries \n",
    "   \n",
    "for idx, row in sites[:20].iterrows():\n",
    "    \n",
    "    print(\"Processings site no {}\".format(row.id))\n",
    "    \n",
    "    # Make geom to submit to EE \n",
    "    x,y = row.geometry.buffer(0.0001).envelope.exterior.coords.xy\n",
    "    coords = [list(zip(x,y))]\n",
    "    area = ee.Geometry.Polygon(coords)\n",
    "    \n",
    "    # Get the corresponding SCAN data file from data folder\n",
    "    site_id = row.id\n",
    "    sm_file = [os.path.join(data_dir,x) for x in os.listdir(data_dir) if site_id in x][0]\n",
    "    sm_dat = read_sm_file(sm_file)\n",
    "    sm_dat['Date'] =  pd.to_datetime(sm_dat['Date'], format='%Y%m%d %H:%M')\n",
    "    sm_dat.set_index('Date', inplace=True)\n",
    "        \n",
    "    # start and end date\n",
    "    startdate = sm_dat.index[0]\n",
    "    enddate = sm_dat.index[-1]\n",
    "    \n",
    "    date = startdate.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Select the nlcd dataset\n",
    "    dataset =  rs.load_data()['nlcd']\n",
    "    ic = dataset[0]\n",
    "    var = dataset[1]\n",
    "    res = dataset[3]\n",
    "    \n",
    "    # find the nearest nlcd dataset \n",
    "    col = ic.filterDate(ee.Date(date).advance(-1, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    t = col.reduceRegion(ee.Reducer.frequencyHistogram(), area, res).get(var)\n",
    "    meta = col.getInfo()\n",
    "    lc_class = int(list(t.getInfo().keys())[0])\n",
    "    \n",
    "    # Get the landcover type\n",
    "    lcidx = meta['properties']['landcover_class_values'].index(lc_class)\n",
    "    lctype = meta['properties']['landcover_class_names'][lcidx]\n",
    "    print(lctype)\n",
    "    \n",
    "    # Get Sentinel images and dates (ascending orbits only, VV polarization)\n",
    "    s1 = rs.load_data()['s1']\n",
    "    s1ic, s1var, s1res = s1[0], s1[1], s1[3]\n",
    "    \n",
    "    s1_col = s1ic.filterBounds(area).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "    s1_col = s1_col.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).select(s1var)\n",
    "    \n",
    "    # Krishna used ascending pass... \n",
    "    \n",
    "    s1_col = s1_col.filterDate(startdate,enddate)\n",
    "    t = s1_col.sort('system:time_start')\n",
    "    ims = t.toList(t.size())\n",
    "    \n",
    "    print(\"Processing {} sentinel overapasses\".format(len(ims.getInfo())))\n",
    "\n",
    "    s1dat, dates = get_ims_by_date(ims,s1var)\n",
    "    \n",
    "    # Calc the S1 mean backscatter in each image\n",
    "    mean_sigmas = []\n",
    "    std_sigmas = []\n",
    "\n",
    "    for i in s1dat:\n",
    "        mean_sigmas.append(np.mean(i))\n",
    "        std_sigmas.append(np.std(i))\n",
    "        \n",
    "    # Convert the datestrings from S1 to pandas datetimes \n",
    "    for idx, x in enumerate(dates):\n",
    "        timestamp = x.find(\"1SDV_\")+5\n",
    "        timestr = x[timestamp:timestamp+13]\n",
    "        dates[idx] = pd.to_datetime(timestr, format='%Y%m%d %H:%M')\n",
    "        \n",
    "    # Get PRISM data for all the S1 overpass dates to filter the rainy days\n",
    "    print(\"processing PRISM\")\n",
    "    rainfall = []\n",
    "\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "        \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "        t = filter_date(rs.load_data()['prism_daily'][0], y, m, d).sum()\n",
    "        precip_total = get_2day_precip(t, area)\n",
    "        rainfall.append(precip_total)\n",
    "\n",
    "    \n",
    "    # MODIS LAI \n",
    "    print(\"processing MODIS\")\n",
    "    modis = rs.load_data()['modis_lai']\n",
    "    mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "    modis_lai = []\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "            \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "        start = ee.Date.fromYMD(y,m,d).advance(-2,\"day\")\n",
    "        end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "        prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()\n",
    "\n",
    "        try:\n",
    "            res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=5) # Need to have scale smaller than geom\n",
    "            data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "            out = np.array(data)* 0.1\n",
    "            modis_lai.append(out)\n",
    "        except:\n",
    "            out = np.nan\n",
    "            modis_lai.append(np.nan)\n",
    "        \n",
    "        print(out)\n",
    "                \n",
    "    # Filter the SCAN data for the S1 dates, 3 am - 7 am \n",
    "    rzsm = []\n",
    "    ssm = []\n",
    "    \n",
    "    for i in dates:\n",
    "        starttime = i.replace(second=0, microsecond=0, minute=0, hour=3)\n",
    "        endtime = starttime+timedelta(hours= 4)\n",
    "        df = pd.DataFrame(sm_dat[starttime:endtime])\n",
    "        \n",
    "        rzsm.append(df[df.columns[-1]].values)\n",
    "        ssm.append(df[df.columns[-3]].values)\n",
    "    \n",
    "    # In case there are nans or data gaps in the sm data\n",
    "    rzsm = [list(filter(None, x)) for x in rzsm]\n",
    "    ssm = [list(filter(None, x)) for x in ssm]\n",
    "    \n",
    "    # Calc the 5 hour mean for each sensor reading \n",
    "    for idx,x in enumerate(rzsm):\n",
    "        rzsm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "    \n",
    "    for idx,x in enumerate(ssm):\n",
    "        ssm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "\n",
    "    # params to calculate psi \n",
    "    a = row.a\n",
    "    b = row.b\n",
    "    \n",
    "    # RZ and Surface LWP = A * sm ^b\n",
    "    psi1 = [a*(x/100)**b for x in rzsm]\n",
    "    psi2 = [a*(x/100)**b for x in ssm]\n",
    "    \n",
    "    df = pd.DataFrame([dates, mean_sigmas, rainfall, modis_lai, rzsm,psi1,ssm,psi2])\n",
    "    df = df.T\n",
    "    df.columns = (['date', \"sigma\",\"precip\",\"LAI\", \"rzsm\",\"psi_rz\", \"ssm\", \"psi_s\"])\n",
    "    mask=(df['precip'] < 0.1)\n",
    "    dfout = df[mask]\n",
    "    \n",
    "    dfs.append(dfout)\n",
    "    \n",
    "    print(dfout.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % \n",
      "1.2000000000000002\n"
     ]
    }
   ],
   "source": [
    "modis = rs.load_data()['modis_lai']\n",
    "mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "modis_lai = []\n",
    "for i,x in enumerate(dates[:1]):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "    sd = ee.Date.fromYMD(y,m,d).advance(-2,\"day\")\n",
    "    ed = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "    prod = mic.filterDate(sd, ed).sort('system:time_start').select(mvar).first()\n",
    "\n",
    "    try:\n",
    "        res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=5) # Need to have scale smaller than geom\n",
    "        data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "        out = np.array(data)* 0.1\n",
    "        modis_lai.append(out)\n",
    "    except:\n",
    "        out = np.nan\n",
    "        modis_lai.append(np.nan)\n",
    "\n",
    "    print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "EEException",
     "evalue": "Date.fromYMD: Bad year/month/day: 2016/9/-1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-66361cbf7904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/gis/lib/python3.6/site-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/gis/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mevaluating\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m   \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msend_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'json_format'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'v2'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/gis/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36msend_\u001b[0;34m(path, params, opt_method, opt_raw)\u001b[0m\n\u001b[1;32m   1184\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid JSON: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'data'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Malformed response: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEEException\u001b[0m: Date.fromYMD: Bad year/month/day: 2016/9/-1."
     ]
    }
   ],
   "source": [
    "sd.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_lai = []\n",
    "res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=5) # Need to have scale smaller than geom\n",
    "data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "out = np.array(data)\n",
    "modis_lai.append(out*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6000000000000001]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modis_lai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing MODIS\n",
      "0\n",
      "7\n",
      "1\n",
      "34\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "nan\n",
      "6\n",
      "1\n",
      "7\n",
      "1\n",
      "8\n",
      "1\n",
      "9\n",
      "1\n",
      "10\n",
      "1\n",
      "11\n",
      "2\n",
      "12\n",
      "2\n",
      "13\n",
      "3\n",
      "14\n",
      "4\n",
      "15\n",
      "5\n",
      "16\n",
      "4\n",
      "17\n",
      "10\n",
      "18\n",
      "2\n",
      "19\n",
      "15\n",
      "20\n",
      "27\n",
      "21\n",
      "31\n",
      "22\n",
      "7\n",
      "23\n",
      "6\n",
      "24\n",
      "7\n",
      "25\n",
      "6\n",
      "26\n",
      "3\n",
      "27\n",
      "5\n",
      "28\n",
      "7\n",
      "29\n",
      "12\n",
      "30\n",
      "17\n",
      "31\n",
      "0\n",
      "32\n",
      "10\n",
      "33\n",
      "10\n",
      "34\n",
      "5\n",
      "35\n",
      "6\n",
      "36\n",
      "15\n",
      "37\n",
      "12\n",
      "38\n",
      "31\n",
      "39\n",
      "50\n",
      "40\n",
      "18\n",
      "41\n",
      "8\n",
      "42\n",
      "5\n",
      "43\n",
      "10\n",
      "44\n",
      "6\n",
      "45\n",
      "3\n",
      "46\n",
      "nan\n",
      "47\n",
      "3\n",
      "48\n",
      "3\n",
      "49\n",
      "2\n",
      "50\n",
      "1\n",
      "51\n",
      "nan\n",
      "52\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"processing MODIS\")\n",
    "modis = rs.load_data()['modis_lai']\n",
    "mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "modis_lai = []\n",
    "for i,x in enumerate(dates):\n",
    "    print(i)\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day -2 \n",
    "\n",
    "    start = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d).advance(10, \"day\")\n",
    "\n",
    "    prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()\n",
    "\n",
    "    try:\n",
    "        res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=10)\n",
    "        data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "        out = np.array(data)\n",
    "        modis_lai.append(out*0.1)\n",
    "    except:\n",
    "        out = np.nan\n",
    "        modis_lai.append(np.nan)\n",
    "\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = ee.Date.fromYMD(2011,10,4).advance(-2,\"day\")\n",
    "end = ee.Date.fromYMD(2011,10,4).advance(5, \"day\")\n",
    "\n",
    "\n",
    "prod = mic.filterDate(start, end).sort('system:time_start').select(\"Lai\").first()\n",
    "res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lai': 4}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "EEException",
     "evalue": "Array: Parameter 'values' is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-418ac49b5cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lai\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/gis/lib/python3.6/site-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/gis/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mevaluating\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m   \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msend_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'json_format'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'v2'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/gis/lib/python3.6/site-packages/ee/data.py\u001b[0m in \u001b[0;36msend_\u001b[0;34m(path, params, opt_method, opt_raw)\u001b[0m\n\u001b[1;32m   1184\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid JSON: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'data'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mee_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Malformed response: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEEException\u001b[0m: Array: Parameter 'values' is required."
     ]
    }
   ],
   "source": [
    "# res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "data = np.array((ee.Array(res.get(\"Lai\")).getInfo()))\n",
    "out = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lai': None}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis = rs.load_data()['modis_lai']\n",
    "mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "modis_lai = []\n",
    "for i,x in enumerate(dates):\n",
    "    print(i)\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-2, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "    prod = mic.filterDate(start, end).sort('system:time_start', False).first().select(\"Fpar\")\n",
    "\n",
    "    try:\n",
    "        res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=500)\n",
    "        data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "        out = np.array(data)\n",
    "        modis_lai.append(out*0.1)\n",
    "    except:\n",
    "        out = np.nan\n",
    "        modis_lai.append(np.nan)\n",
    "\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis = rs.load_data()['modis_lai']\n",
    "mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "modis_lai = []\n",
    "for i,x in enumerate(dates):\n",
    "    print(i)\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-2, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "    prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar)\n",
    "\n",
    "    try:\n",
    "        res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=500)\n",
    "        data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "        out = np.array(data)\n",
    "        modis_lai.append(out*0.1)\n",
    "    except:\n",
    "        out = np.nan\n",
    "        modis_lai.append(np.nan)\n",
    "\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates[0]\n",
    "\n",
    "print(dates[0])\n",
    "\n",
    "y,m,d = dates[0].year, dates[0].month, dates[0].day\n",
    "\n",
    "start = ee.Date.fromYMD(y,m,d).advance(-3, \"day\")\n",
    "end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "prod = mic.filterDate(start, end).sort('system:time_start', False).first()\n",
    "\n",
    "\n",
    "\n",
    "print(prod.get(\"Lai\").getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE --> Numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_from_latlon(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"VV\")).getInfo()))\n",
    "    lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "    lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def array_from_latlon_ppt(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "    lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def make_np_array(data, lats, lons):\n",
    "    # get data from df as arrays\n",
    "    lons = np.array(lons)\n",
    "    lats = np.array(lats)\n",
    "    data = np.array(data) # Set var here \n",
    "                                              \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32)\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] # we start from lower left corner\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def get_ims_by_date(ims_list):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (1, num_images):\n",
    "        print(i)\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon))\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "\n",
    "    return imlist, imdates\n",
    "\n",
    "#     times = []\n",
    "#     for i in imdates:\n",
    "#         time_idx = i.find(\"T0\")\n",
    "#         ymd = i[time_idx-8:time_idx]\n",
    "#         hms = i[time_idx+1:time_idx+7]\n",
    "#         times.append(datetime.strptime(ymd+hms, '%Y%m%d%H%M%S'))\n",
    "\n",
    "\n",
    "def get_ims_dates_ppt(ims_list):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (1, num_images):\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon_ppt(latlon))\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "    \n",
    "    times = []\n",
    "    for i in imdates:\n",
    "        time_idx = i.find(\"T0\")\n",
    "        ymd = i[time_idx-8:time_idx]\n",
    "        hms = i[time_idx+1:time_idx+7]\n",
    "        times.append(datetime.strptime(ymd+hms, '%Y%m%d%H%M%S'))\n",
    "\n",
    "    return imlist, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = glob.glob(\"*.csv\")\n",
    "txts = glob.glob(\"*.txt\")\n",
    "site_file = txts[0]\n",
    "stations_csv = csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract soil moisture site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_no = ''.join(c for c in site_file if c.isdigit())\n",
    "data = read_file(site_file)\n",
    "lat, lon = get_site_lat_lons(site_no,stations_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for each site id\n",
    "# get the sm data file from \"data\" folder \n",
    "# Transform SM to LWP using a, b coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ids = []\n",
    "for i in sites.site_name:\n",
    "    sid = i.split('(')\n",
    "    site_ids.append(sid[1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites['id'] = site_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites.to_file(\"../shape/scan_sites.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ee Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10 # meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = ee.Geometry.Point([lon, lat])\n",
    "area = pt.buffer(buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the RS products to be queried, sort from oldest im first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = ee.ImageCollection('COPERNICUS/S1_GRD').filterBounds(pt).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).select('VV')\n",
    "col = collection.filterDate('2014-10-03','2018-10-03')\n",
    "t = col.sort('system:time_start')\n",
    "ims = t.toList(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ims and sort out the dates to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ims.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1dat, dates = get_ims_dates(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] =  pd.to_datetime(data['Date'], format='%Y%m%d %H:%M')\n",
    "data.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round each startdate to the nearest hour, grab the data that matches that hour \n",
    "rzsm = []\n",
    "ssm = []\n",
    "\n",
    "for i in dates:\n",
    "    start = i.replace(second=0, microsecond=0, minute=0, hour=i.hour)+timedelta(hours=i.minute//30)\n",
    "    df = pd.DataFrame(data.loc[start]).T.astype(np.float)\n",
    "    rzsm.append(df[df.columns[-1]].values)\n",
    "    ssm.append(df[df.columns[-3]].values)\n",
    "\n",
    "rzsm = [x for l in rzsm for x in l]\n",
    "ssms = [x for l in ssm for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rzsm = [x for l in rzsm for x in l]\n",
    "ssms = [x for l in ssm for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sigmas = []\n",
    "\n",
    "for i in s1dat:\n",
    "    mean_sigmas.append(np.mean(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(mean_sigmas)\n",
    "x = x.reshape(x.shape[0])\n",
    "y = np.array(rzsm)\n",
    "y = y.reshape(y.shape[0])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture \n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], \"10\"))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(mean_sigmas, rzsm, label = 'rzsm')\n",
    "plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"$\\sigma$ (dB)\", color=color)\n",
    "ax1.plot(dates, mean_sigmas, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the days with high preceding rainfall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''2 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"Precip (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test with 4 day precip accumulation\n",
    "\n",
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-4, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])\n",
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])\n",
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''4 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"3 day precipitation (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation (4 days)\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
