{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import ee\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rsfuncs as rs\n",
    "\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18,16]\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE functions are in the rsfuncs module. Loacal functions are here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sm_file(filename):\n",
    "    with open(filename) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in contents:\n",
    "        if line[0:1] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            data.append(line)\n",
    "\n",
    "    headers = [x.replace(\"Soil Moisture Percent\",\"smp\").replace(\" \",\"_\") for x in data[0].split(\",\")]\n",
    "    cols = [x.strip(\"\\n\").split(\",\") for x in data[1:]]\n",
    "\n",
    "    df = pd.DataFrame(cols, columns = headers)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_ims_by_date(ims_list, var, res=10):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (0, num_images):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_images)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon, var, res))\n",
    "        date =  latlon.get('system:time_start')\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "\n",
    "    return imlist, imdates\n",
    "\n",
    "def array_from_latlon(latlon_obj, var, res ):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=res)\n",
    "    try:\n",
    "        lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "        lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "        data = np.array((ee.Array(res.get(var)).getInfo()))\n",
    "    except:\n",
    "        data = np.full_like(lats, np.nan,dtype=np.float64)\n",
    "    \n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def make_np_array(data, lats, lons):\n",
    "    # get data from df as arrays\n",
    "    lons = np.array(lons)\n",
    "    lats = np.array(lats)\n",
    "    data = np.array(data) # Set var here \n",
    "                                              \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32)\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] # we start from lower left corner\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_file = gp.read_file(\"../shape/scan_sites.shp\")\n",
    "sites = site_file[~site_file['state'].isin([\"AK\", \"HI\", \"PR\", \"VI\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processings site no 2018\n",
      "Shrub/Scrub - Areas dominated by shrubs; less than 5 meters tall with shrub canopy typically greater than 20% of total vegetation. This class includes true shrubs, young trees in an early successional stage or trees stunted from environmental conditions.\n",
      "no valid overpasses\n",
      "Processings site no 2003\n",
      "Deciduous Forest - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species shed foliage simultaneously in response to seasonal change.\n",
      "no valid overpasses\n",
      "Processings site no 2196\n",
      "Sedge/Herbaceous - Alaska only areas dominated by sedges and forbs, generally greater than 80% of total vegetation. This type can occur with significant other grasses or other grass like plants, and includes sedge tundra, and sedge tussock tundra.\n",
      "no valid overpasses\n",
      "Processings site no 2021\n",
      "Sedge/Herbaceous - Alaska only areas dominated by sedges and forbs, generally greater than 80% of total vegetation. This type can occur with significant other grasses or other grass like plants, and includes sedge tundra, and sedge tussock tundra.\n",
      "Processing 88 sentinel overapasses\n",
      "0.0 % \n"
     ]
    }
   ],
   "source": [
    "# For each site id, find the sm file with the data (in data dir), \n",
    "# calculate psi as psi = A * SM ^b (krishna's paper )\n",
    "# query the (1) landcover, (2) Sentinel backscatter (Prism P), MODIS / Landsat LAI for the whole timeseries \n",
    "   \n",
    "for idx, row in sites[::-1].iterrows():\n",
    "    \n",
    "    print(\"Processings site no {}\".format(row.id))\n",
    "    \n",
    "    # Make geom to submit to EE \n",
    "    x,y = row.geometry.buffer(0.0001).envelope.exterior.coords.xy\n",
    "    coords = [list(zip(x,y))]\n",
    "    area = ee.Geometry.Polygon(coords)\n",
    "    \n",
    "    # Get the corresponding SCAN data file from data folder\n",
    "    site_id = row.id\n",
    "    sm_file = [os.path.join(data_dir,x) for x in os.listdir(data_dir) if site_id in x][0]\n",
    "    sm_dat = read_sm_file(sm_file)\n",
    "    sm_dat['Date'] =  pd.to_datetime(sm_dat['Date'], format='%Y%m%d %H:%M')\n",
    "    sm_dat.set_index('Date', inplace=True)\n",
    "        \n",
    "    # start and end date\n",
    "    startdate = sm_dat.index[0]\n",
    "    enddate = sm_dat.index[-1]\n",
    "    \n",
    "    date = startdate.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    # Select the nlcd dataset\n",
    "    dataset =  rs.load_data()['nlcd']\n",
    "    ic = dataset[0]\n",
    "    var = dataset[1]\n",
    "    res = dataset[3]\n",
    "    \n",
    "    # find the nearest nlcd dataset \n",
    "    col = ic.filterDate(ee.Date(date).advance(-1, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    if not col.getInfo():\n",
    "        col = ic.filterDate(ee.Date(date).advance(-3, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    t = col.reduceRegion(ee.Reducer.frequencyHistogram(), area, res).get(var)\n",
    "    meta = col.getInfo()\n",
    "    try:\n",
    "        lc_class = int(list(t.getInfo().keys())[0])\n",
    "    except:\n",
    "        lc_class = \"None\"\n",
    "    \n",
    "    # Get the landcover type\n",
    "    lcidx = meta['properties']['landcover_class_values'].index(lc_class)\n",
    "    lctype = meta['properties']['landcover_class_names'][lcidx]\n",
    "    print(lctype)\n",
    "    \n",
    "    # Get Sentinel images and dates (ascending orbits only, VV polarization)\n",
    "    s1 = rs.load_data()['s1']\n",
    "    s1ic, s1var, s1res = s1[0], s1[1], s1[3]\n",
    "    \n",
    "    s1_col = s1ic.filterBounds(area).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "    s1_col = s1_col.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).select(s1var)\n",
    "    \n",
    "    # Krishna used ascending pass... I think descending is the correct orbit for the AM \n",
    "    \n",
    "    s1_col = s1_col.filterDate(startdate,enddate)\n",
    "    t = s1_col.sort('system:time_start')\n",
    "    \n",
    "    try:\n",
    "        ims = t.toList(t.size())\n",
    "        print(\"Processing {} sentinel overapasses\".format(len(ims.getInfo())))\n",
    "        s1dat, dates = get_ims_by_date(ims,s1var)\n",
    "        \n",
    "    except:\n",
    "        print(\"no valid overpasses\")\n",
    "        continue\n",
    "    \n",
    "    # Calc the S1 backscatter in each image\n",
    "    mean_sigmas = []\n",
    "    std_sigmas = []\n",
    "\n",
    "    for i in s1dat:\n",
    "        mean_sigmas.append(np.mean(i))\n",
    "        std_sigmas.append(np.std(i))\n",
    "        \n",
    "    # Convert the datestrings from S1 to pandas datetimes \n",
    "    for idx, x in enumerate(dates):\n",
    "        timestamp = x.find(\"V_\")+2\n",
    "        timestr = x[timestamp:timestamp+13]\n",
    "        dates[idx] = pd.to_datetime(timestr, format='%Y%m%d %H:%M')\n",
    "        \n",
    "    # Get PRISM data for all the S1 overpass dates to filter the rainy days\n",
    "    print(\"processing PRISM\")\n",
    "    rainfall = []\n",
    "\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "        \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "        t = filter_date(rs.load_data()['prism_daily'][0], y, m, d).sum()\n",
    "        precip_total = get_2day_precip(t, area)\n",
    "        rainfall.append(precip_total)\n",
    "\n",
    "    \n",
    "    # MODIS LAI \n",
    "    print(\"processing MODIS\")\n",
    "    modis = rs.load_data()['modis_lai']\n",
    "    mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "    modis_lai = []\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "            \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "        start = ee.Date.fromYMD(y,m,d).advance(-2,\"day\")\n",
    "        end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "        prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()\n",
    "\n",
    "        try:\n",
    "            res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=5) # Need to have scale smaller than geom\n",
    "            data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "            out = np.array(data)* 0.1\n",
    "            modis_lai.append(out)\n",
    "        except:\n",
    "            out = np.nan\n",
    "            modis_lai.append(np.nan)\n",
    "            \n",
    "    # Landsat - Note: some sites are in the overlap areas between passes.\n",
    "    # these sites can have multiple obs / day or obs separated by 8days instead of 16. \n",
    "    \n",
    "    print(\"Processing Landsat\")\n",
    "    landsat = rs.load_data()['l8_sr']\n",
    "    lic, lvar, lsf = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "    lstart = ee.Date.fromYMD(startdate.year,startdate.month,startdate.day).advance(-16,\"day\")\n",
    "    lend = ee.Date.fromYMD(enddate.year,enddate.month,enddate.day).advance(16, \"day\")\n",
    "\n",
    "    l8_col = lic.filterDate(lstart,lend).filterBounds(area).map(rs.mask_quality) # Mask clouds and shadows \n",
    "    lt = l8_col.sort('system:time_start')\n",
    "    lims = lt.toList(lt.size())\n",
    "\n",
    "    num_ims = len(lims.getInfo())\n",
    "\n",
    "    ldfs = []\n",
    "\n",
    "    for i in range (0, num_ims):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "        ls_latlon = ee.Image.pixelLonLat().addBands(lims.get(i))\n",
    "        ltemp = ls_latlon.select([\"B1\", \"B4\", \"B5\"]).multiply(lsf)\n",
    "        l8_res = ltemp.reduceRegion(reducer=ee.Reducer.mean(),geometry=area,bestEffort=True,scale=30)\n",
    "\n",
    "        l8_info_dict = lims.get(i).getInfo()\n",
    "        l8_date = l8_info_dict['id'][-8:]\n",
    "\n",
    "        l8_out = l8_res.getInfo()\n",
    "\n",
    "        ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "        ldf.columns = l8_out.keys()\n",
    "        ldf.index = pd.to_datetime([l8_date])\n",
    "        ldfs.append(ldf)\n",
    "                                \n",
    "    # Filter the SCAN data for the S1 dates, 3 am - 7 am \n",
    "    rzsm = []\n",
    "    ssm = []\n",
    "    \n",
    "    for i in dates:\n",
    "        starttime = i.replace(second=0, microsecond=0, minute=0, hour=3)\n",
    "        endtime = starttime+timedelta(hours= 4)\n",
    "        df = pd.DataFrame(sm_dat[starttime:endtime])\n",
    "        \n",
    "        rzsm.append(df[df.columns[-1]].values)\n",
    "        ssm.append(df[df.columns[-3]].values)\n",
    "    \n",
    "    # In case there are nans or data gaps in the sm data\n",
    "    rzsm = [list(filter(None, x)) for x in rzsm]\n",
    "    ssm = [list(filter(None, x)) for x in ssm]\n",
    "    \n",
    "    # Calc the 5 hour mean for each sensor reading \n",
    "    for idx,x in enumerate(rzsm):\n",
    "        rzsm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "    \n",
    "    for idx,x in enumerate(ssm):\n",
    "        ssm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "\n",
    "    # params to calculate psi \n",
    "    a = row.a\n",
    "    b = row.b\n",
    "    \n",
    "    # RZ and Surface LWP = A * sm ^b\n",
    "    psi1 = [a*(x/100)**b for x in rzsm]\n",
    "    psi2 = [a*(x/100)**b for x in ssm]\n",
    "    \n",
    "    # Make a dataframe out of everything\n",
    "    df = pd.DataFrame([dates, mean_sigmas, std_sigmas, rainfall, modis_lai, rzsm,psi1,ssm,psi2])\n",
    "    df = df.T\n",
    "    df.columns = (['date', \"sigma\", \"std_sigma\", \"precip\",\"LAI\", \"rzsm\",\"psi_rz\", \"ssm\", \"psi_s\"])\n",
    "    df = rs.col_to_dt(df) # set the date col as datetime index \n",
    "    mask=(df['precip'] < 0.1)\n",
    "    dfout = df[mask]\n",
    "\n",
    "    # For now append the nearest landsat image band values to the master df \n",
    "    # TODO: Golay interpolation \n",
    "    \n",
    "    ls = pd.concat(ldfs)\n",
    "    ls_df = ls[(ls.T != 0).any()]\n",
    "    ls_df = ls_df.groupby(level = 0).mean()\n",
    "    \n",
    "    # Break the loop if there are no non- rainy sentinel overpasses \n",
    "    if dfout.empty:\n",
    "        print(\"No non-rainy overpaasses \")\n",
    "        continue \n",
    "        \n",
    "    l8_dfs = []\n",
    "    \n",
    "    for i in dfout.index:\n",
    "        l8_idx = ls_df.index.get_loc(i, method='nearest')\n",
    "        l8_contemp = ls_df.iloc[l8_idx]\n",
    "        t = pd.DataFrame(l8_contemp).T\n",
    "        l8_dfs.append(t)\n",
    "    \n",
    "    fin_ls = pd.concat(l8_dfs)\n",
    "\n",
    "    FIN = pd.concat( [dfout.reset_index(drop=True), fin_ls.reset_index(drop=True)], axis=1) \n",
    "    FIN.index = dfout.index\n",
    "\n",
    "    print(FIN.head())\n",
    "    \n",
    "    out_dict[(row.id)] = FIN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = ls[(ls.T != 0).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = pd.concat(ls_dfs[1])\n",
    "df2 = ls[(ls.T != 0).any()]\n",
    "\n",
    "df = rs.col_to_dt(df)\n",
    "ls_df = ls[(ls.T != 0).any()]\n",
    "\n",
    "for i in df.index:\n",
    "    l8_idx = df2.index.get_loc(i, method='nearest')\n",
    "    l8_contemp = df2.iloc[l8_idx]\n",
    "    t = pd.DataFrame(l8_contemp).T\n",
    "    t.reset_index(drop=True, inplace=True)\n",
    "    df[t.columns] = t.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[t.columns] = t.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = sm_dat.index[0]\n",
    "enddate = sm_dat.index[-1]\n",
    "    \n",
    "\n",
    "landsat = rs.load_data()['l8_sr']\n",
    "lic, lvar, lsf = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "lstart = ee.Date.fromYMD(startdate.year,startdate.month,startdate.day).advance(-16,\"day\")\n",
    "lend = ee.Date.fromYMD(enddate.year,enddate.month,enddate.day).advance(16, \"day\")\n",
    "\n",
    "l8_col = lic.filterDate(lstart,lend).filterBounds(area).map(rs.mask_quality)\n",
    "lt = l8_col.sort('system:time_start')\n",
    "lims = lt.toList(lt.size())\n",
    "\n",
    "num_ims = len(lims.getInfo())\n",
    "\n",
    "ldfs = []\n",
    "\n",
    "for i in range (0, num_ims):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "    ls_latlon = ee.Image.pixelLonLat().addBands(lims.get(i))\n",
    "    ltemp = ls_latlon.select([\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"]).multiply(lsf)\n",
    "    l8_res = ltemp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=30)\n",
    "\n",
    "    l8_info_dict = lims.get(i).getInfo()\n",
    "    l8_date = l8_info_dict['id'][-8:]\n",
    "\n",
    "    l8_out = l8_res.getInfo()\n",
    "\n",
    "    ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "    ldf.columns = l8_out.keys()\n",
    "    ldf.index = pd.to_datetime([l8_date])\n",
    "    ldfs.append(ldf)\n",
    "    print(ldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(2).getInfo()['properties']['system:index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(3).getInfo()['properties']['system:index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(10).getInfo()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(11).getInfo()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims.get(0).getInfo()['properties']['system:index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()\n",
    "landsat = data['l8_sr']\n",
    "lic, lvar, lsf = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "start = ee.Date.fromYMD(startdate.year,startdate.month,startdate.day).advance(8,\"day\")\n",
    "end = ee.Date.fromYMD(enddate.year,enddate.month,enddate.day).advance(8, \"day\")\n",
    "\n",
    "l8_col = lic.filterDate(start,end).filterBounds(area).map(rs.mask_quality)\n",
    "t = l8_col.sort('system:time_start')\n",
    "ims = t.toList(t.size())\n",
    "\n",
    "num_ims = len(ims.getInfo())\n",
    "\n",
    "ldfs = []\n",
    "\n",
    "for i in range (0, num_ims):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "    latlon = ee.Image.pixelLonLat().addBands(ims.get(i))\n",
    "    temp = latlon.select([\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"]).multiply(lsf)\n",
    "    res = temp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,scale=30)\n",
    "    info_dict = lims.get(i).getInfo()\n",
    "    l8_date = info_dict['id'][-8:]\n",
    "\n",
    "    l8_out = res.getInfo()\n",
    "\n",
    "    ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "    ldf.columns = l8_out.keys()\n",
    "    ldf.index = pd.to_datetime([l8_date])\n",
    "    ldfs.append(ldf)\n",
    "    \n",
    "    print(ldf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_out = res.getInfo()\n",
    "\n",
    "ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "ldf.columns = l8_out.keys()\n",
    "ldf.index = pd.to_datetime([l8_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_d1.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()\n",
    "\n",
    "landsat = data['l8_sr']\n",
    "lic, lvar, lres = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "sd = \n",
    "\n",
    "l8_col = lic.filterDate(ee.Date(startdate).advance(\"day\", -16),ee.Date(enddate).advance(\"day\", 16)).filterBounds(area)\n",
    "t = l8_col.sort('system:time_start')\n",
    "ims = t.toList(t.size())\n",
    "\n",
    "num_ims = len(ims.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlist = []\n",
    "\n",
    "for i in range (0, num_ims):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims.get(i))\n",
    "        temp = latlon.select([\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"]).getInfo()\n",
    "        res = temp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=30)\n",
    "\n",
    "        \n",
    "#         imlist.append(array_from_latlon(latlon, \"B7\", 30))\n",
    "#         date =  latlon.get('system:time_start')\n",
    "#         info_dict = ims.get(i).getInfo()\n",
    "#         date = info_dict['id']\n",
    "#         imdates.append(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = latlon.select([\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = temp.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (0, num_images):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_images)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon, var, res))\n",
    "        date =  latlon.get('system:time_start')\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "\n",
    "    return imlist, imdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat = data['l8_sr']\n",
    "lic, lvar, lres = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "for i,x in enumerate(dates[:1]):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    \n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-8,\"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d).advance(8, \"day\")\n",
    "\n",
    "    prod = lic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()\n",
    "    l8_im= prod.filterBounds(area).map(rs.mask_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    s1_col = s1_col.filterDate(startdate,enddate)\n",
    "    t = s1_col.sort('system:time_start')\n",
    "    \n",
    "    try:\n",
    "        ims = t.toList(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    band_name = col.select(band).median()\n",
    "    latlon = ee.Image.pixelLonLat().addBands(band_name).multiply(0.0001)\n",
    "\n",
    "    # apply reducer to list\n",
    "    latlon = latlon.reduceRegion(\n",
    "      reducer=ee.Reducer.toList(),\n",
    "      geometry=bounds,\n",
    "      maxPixels=1e13,\n",
    "      scale=res)\n",
    "    \n",
    "    data = np.array((ee.Array(latlon.get(band)).getInfo()))\n",
    "    lats = np.array((ee.Array(latlon.get(\"latitude\")).getInfo()))\n",
    "    lons = np.array((ee.Array(latlon.get(\"longitude\")).getInfo()))\n",
    "    \n",
    "    arr = array_from_coords(data,lats,lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    if i % 5 == 0:\n",
    "        print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-2,\"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "    prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(mean_sigmas)\n",
    "x = x.reshape(x.shape[0])\n",
    "y = np.array(rzsm)\n",
    "y = y.reshape(y.shape[0])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture \n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], \"10\"))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(mean_sigmas, rzsm, label = 'rzsm')\n",
    "plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"$\\sigma$ (dB)\", color=color)\n",
    "ax1.plot(dates, mean_sigmas, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the days with high preceding rainfall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''2 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"Precip (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test with 4 day precip accumulation\n",
    "\n",
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-4, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])\n",
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])\n",
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''4 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"3 day precipitation (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation (4 days)\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py 3 gis",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
