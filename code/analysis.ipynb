{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import ee\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rsfuncs as rs\n",
    "\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18,16]\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE functions are in the rsfuncs module. Loacal functions are here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sm_file(filename):\n",
    "    with open(filename) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in contents:\n",
    "        if line[0:1] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            data.append(line)\n",
    "\n",
    "    headers = [x.replace(\"Soil Moisture Percent\",\"smp\").replace(\" \",\"_\") for x in data[0].split(\",\")]\n",
    "    cols = [x.strip(\"\\n\").split(\",\") for x in data[1:]]\n",
    "\n",
    "    df = pd.DataFrame(cols, columns = headers)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_file = gp.read_file(\"../shape/scan_sites.shp\")\n",
    "sites = site_file[~site_file['state'].isin([\"AK\", \"HI\", \"PR\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deciduous Forest - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species shed foliage simultaneously in response to seasonal change.\n"
     ]
    }
   ],
   "source": [
    "# For each site id, find the sm file with the data (in data dir), \n",
    "# calculate psi as psi = A * SM ^b (krishna's paper )\n",
    "# query the (1) landcover, (2) Sentinel backscatter (Prism P), MODIS / Landsat LAI for the whole timeseries \n",
    "   \n",
    "for idx, row in sites[:1].iterrows():\n",
    "    \n",
    "    # Get the corresponding soil moisture file from data folder\n",
    "    site_id = row.id\n",
    "    sm_file = [os.path.join(data_dir,x) for x in os.listdir(data_dir) if site_id in x][0]\n",
    "    sm_dat = read_sm_file(sm_file)\n",
    "    \n",
    "    # Make geom to submit to EE \n",
    "    x,y = row.geometry.buffer(0.0001).envelope.exterior.coords.xy\n",
    "    coords = [list(zip(x,y))]\n",
    "    area = ee.Geometry.Polygon(coords)\n",
    "        \n",
    "    # start and end date\n",
    "    sm_dat.Date = pd.to_datetime(sm_dat.Date)\n",
    "    startdate = sm_dat.Date.iloc[0]\n",
    "    enddate = sm_dat.Date.iloc[-1]\n",
    "    \n",
    "    date = startdate.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Select the nlcd dataset\n",
    "    dataset =  data['nlcd']\n",
    "    ic = dataset[0]\n",
    "    var = dataset[1]\n",
    "    res = dataset[3]\n",
    "    \n",
    "    # find the nearest nlcd dataset \n",
    "    col = ic.filterDate(ee.Date(date).advance(-1, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    t = col.reduceRegion(ee.Reducer.mean(), area, res).get(var)\n",
    "    meta = col.getInfo()\n",
    "    lctype = t.getInfo()\n",
    "    \n",
    "    # Get the landcover type\n",
    "    lcidx = meta['properties']['landcover_class_values'].index(lctype)\n",
    "    lctype = meta['properties']['landcover_class_names'][lcidx]\n",
    "    print(lctype)\n",
    "    \n",
    "    # Get the other datasets. Start with sentinel. \n",
    "    \n",
    "    # Filter by prism (DAILY)\n",
    "    \n",
    "#     prism = rs.get_ims(data['prism'], range(startdate.year, enddate.year),range(1,13), area) \n",
    "#     prism = rs.get_ims(data['landsat'], range(startdate.year, enddate.year), range(1,13), area) \n",
    "    \n",
    "    # Get the NDVI / AGB - Landsat / MODIS \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # params to calculate psi \n",
    "    a = row.a\n",
    "    b = row.b\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcidx = meta['properties']['landcover_class_values'].index(lctype)\n",
    "lctype = meta['properties']['landcover_class_names'][lcidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    lc = data['nlcd'].filterBounds(pt).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).select('VV')\n",
    "    col = collection.filterDate('2014-10-03','2018-10-03')\n",
    "    t = col.sort('system:time_start')\n",
    "    ims = t.toList(t.size())\n",
    "    \n",
    "    collection = ee.ImageCollection('COPERNICUS/S1_GRD').filterBounds(pt).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).select('VV')\n",
    "    col = collection.filterDate('2014-10-03','2018-10-03')\n",
    "    t = col.sort('system:time_start')\n",
    "    ims = t.toList(t.size())\n",
    "    print(datetime.strftime(startdate, \"%Y%m%d - %h%m%s\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data['cdl'][0].filterDate(startdate,enddate).select('cropland').filterBounds(area).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = t.reduceRegion(reducer=ee.Reducer.toList(), geometry = area, scale = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ee.ImageCollection(\"USDA/NASS/CDL\").filterDate(ee.Date(startdate), ee.Date(startdate).advance(1, 'month')).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = image.reduceRegion(reducer=ee.Reducer.frequencyHistogram(), geometry = area, scale = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ee.ImageCollection(\"USDA/NASS/CDL\")\n",
    "      .filterDate(ee.Date(startdate), ee.Date(startdate).advance(1, 'month')).mean()\n",
    "      .reduceRegion(reducer=ee.Reducer.frequencyHistogram(), geometry = area, scale = 30)\n",
    "      .getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE --> Numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_from_latlon(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"VV\")).getInfo()))\n",
    "    lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "    lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def array_from_latlon_ppt(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "    lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def make_np_array(data, lats, lons):\n",
    "    # get data from df as arrays\n",
    "    lons = np.array(lons)\n",
    "    lats = np.array(lats)\n",
    "    data = np.array(data) # Set var here \n",
    "                                              \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32)\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] # we start from lower left corner\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def get_ims_dates(ims_list):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (1, num_images):\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon))\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "    \n",
    "    times = []\n",
    "    for i in imdates:\n",
    "        time_idx = i.find(\"T0\")\n",
    "        ymd = i[time_idx-8:time_idx]\n",
    "        hms = i[time_idx+1:time_idx+7]\n",
    "        times.append(datetime.strptime(ymd+hms, '%Y%m%d%H%M%S'))\n",
    "\n",
    "    return imlist, times\n",
    "\n",
    "def get_ims_dates_ppt(ims_list):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (1, num_images):\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon_ppt(latlon))\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "    \n",
    "    times = []\n",
    "    for i in imdates:\n",
    "        time_idx = i.find(\"T0\")\n",
    "        ymd = i[time_idx-8:time_idx]\n",
    "        hms = i[time_idx+1:time_idx+7]\n",
    "        times.append(datetime.strptime(ymd+hms, '%Y%m%d%H%M%S'))\n",
    "\n",
    "    return imlist, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = glob.glob(\"*.csv\")\n",
    "txts = glob.glob(\"*.txt\")\n",
    "site_file = txts[0]\n",
    "stations_csv = csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract soil moisture site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_no = ''.join(c for c in site_file if c.isdigit())\n",
    "data = read_file(site_file)\n",
    "lat, lon = get_site_lat_lons(site_no,stations_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for each site id\n",
    "# get the sm data file from \"data\" folder \n",
    "# Transform SM to LWP using a, b coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ids = []\n",
    "for i in sites.site_name:\n",
    "    sid = i.split('(')\n",
    "    site_ids.append(sid[1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites['id'] = site_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites.to_file(\"../shape/scan_sites.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ee Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10 # meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = ee.Geometry.Point([lon, lat])\n",
    "area = pt.buffer(buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the RS products to be queried, sort from oldest im first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = ee.ImageCollection('COPERNICUS/S1_GRD').filterBounds(pt).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).select('VV')\n",
    "col = collection.filterDate('2014-10-03','2018-10-03')\n",
    "t = col.sort('system:time_start')\n",
    "ims = t.toList(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ims and sort out the dates to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ims.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1dat, dates = get_ims_dates(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] =  pd.to_datetime(data['Date'], format='%Y%m%d %H:%M')\n",
    "data.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round each startdate to the nearest hour, grab the data that matches that hour \n",
    "rzsm = []\n",
    "ssm = []\n",
    "\n",
    "for i in dates:\n",
    "    start = i.replace(second=0, microsecond=0, minute=0, hour=i.hour)+timedelta(hours=i.minute//30)\n",
    "    df = pd.DataFrame(data.loc[start]).T.astype(np.float)\n",
    "    rzsm.append(df[df.columns[-1]].values)\n",
    "    ssm.append(df[df.columns[-3]].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rzsm = [x for l in rzsm for x in l]\n",
    "ssms = [x for l in ssm for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sigmas = []\n",
    "\n",
    "for i in s1dat:\n",
    "    mean_sigmas.append(np.mean(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(mean_sigmas)\n",
    "x = x.reshape(x.shape[0])\n",
    "y = np.array(rzsm)\n",
    "y = y.reshape(y.shape[0])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture \n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(mean_sigmas, rzsm, label = 'rzsm')\n",
    "plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"$\\sigma$ (dB)\", color=color)\n",
    "ax1.plot(dates, mean_sigmas, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the days with high preceding rainfall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''2 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"Precip (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test with 4 day precip accumulation\n",
    "\n",
    "imageCollection = ee.ImageCollection(\"OREGONSTATE/PRISM/AN81d\").filterBounds(area)\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-4, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "rainfall = []\n",
    "\n",
    "for i,x in enumerate(dates):\n",
    "    y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "    t = filter_date(imageCollection, y, m, d).sum()\n",
    "    precip_total = get_2day_precip(t)\n",
    "    rainfall.append(precip_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame([dates, mean_sigmas, rzsm, rainfall])\n",
    "fdf = fdf.T\n",
    "fdf.columns = (['date', \"sigma\", \"rzsm\", \"rainfall\"])\n",
    "mask=(fdf['rainfall'] < 0.1)\n",
    "asdf=fdf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "plt.title('''4 day sum Precip (mm) and Soil moisture (%) Time Series\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(dates), dates[0], dates[-1], buffer_size))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('date')\n",
    "ax1.set_ylabel(\"3 day precipitation (mm)\", color=color)\n",
    "ax1.plot(dates, rainfall, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('rzsm', color=color)  \n",
    "ax2.plot(dates,rzsm,color = color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear fit of sigma vs SM\n",
    "x = np.array(asdf['sigma'])\n",
    "x = x.reshape(x.shape[0]).astype(np.float32)\n",
    "y = np.array(asdf['rzsm'])\n",
    "y = y.reshape(y.shape[0]).astype(np.float32)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.title('''$\\sigma$ vs Soil moisture for overpasses without prior precipitation (4 days)\n",
    "          n_overpasses: {}  \n",
    "          startdate: {} \n",
    "          enddate: {}\n",
    "          buffer size: {}m'''.format(len(asdf), asdf['date'].min(), asdf['date'].max(), buffer_size))\n",
    "\n",
    "plt.xlabel(\"Backscatter ($\\sigma$), dB\")\n",
    "plt.scatter(asdf['sigma'],asdf['rzsm'], label = \"rzsm\")\n",
    "# plt.scatter(mean_sigmas, ssm, label = 'ssm')\n",
    "plt.plot(x, intercept + slope*x, 'blue', label='rzsm y = {}x +{}, $r =$ {}'.format(round(slope,1), round(intercept,1), round(r_value,2)))\n",
    "plt.xlabel(\"$\\sigma$ (dB)\")\n",
    "plt.ylabel(\"Soil moisture (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
