{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import ee\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rsfuncs as rs\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18,16]\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE functions are in the rsfuncs module. Loacal functions are here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sm_file(filename):\n",
    "    with open(filename) as f:\n",
    "        contents = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in contents:\n",
    "        if line[0:1] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            data.append(line)\n",
    "\n",
    "    headers = [x.replace(\"Soil Moisture Percent\",\"smp\").replace(\" \",\"_\") for x in data[0].split(\",\")]\n",
    "    cols = [x.strip(\"\\n\").split(\",\") for x in data[1:]]\n",
    "\n",
    "    df = pd.DataFrame(cols, columns = headers)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_ims_by_date(ims_list, var, res=10):\n",
    "    imlist = []\n",
    "    imdates = []\n",
    "    num_images = len(ims_list.getInfo())\n",
    "\n",
    "    for i in range (0, num_images):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_images)*100)[:5] + \" % \")\n",
    "\n",
    "        latlon = ee.Image.pixelLonLat().addBands(ims_list.get(i))\n",
    "        imlist.append(array_from_latlon(latlon, var, res))\n",
    "        date =  latlon.get('system:time_start')\n",
    "        info_dict = ims.get(i).getInfo()\n",
    "        date = info_dict['id']\n",
    "        imdates.append(date)\n",
    "\n",
    "    return imlist, imdates\n",
    "\n",
    "def array_from_latlon(latlon_obj, var, res ):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.toList(),geometry=area,maxPixels=1e8,scale=res)\n",
    "    try:\n",
    "        lats = np.array((ee.Array(res.get(\"latitude\")).getInfo()))\n",
    "        lons = np.array((ee.Array(res.get(\"longitude\")).getInfo()))\n",
    "        data = np.array((ee.Array(res.get(var)).getInfo()))\n",
    "    except:\n",
    "        data = np.full_like(lats, np.nan,dtype=np.float64)\n",
    "    \n",
    "    out = make_np_array(data, lats, lons)\n",
    "    return out   \n",
    "\n",
    "def make_np_array(data, lats, lons):\n",
    "    # get data from df as arrays\n",
    "    lons = np.array(lons)\n",
    "    lats = np.array(lats)\n",
    "    data = np.array(data) # Set var here \n",
    "                                              \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32)\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] # we start from lower left corner\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def filter_date(product,y,m,d):\n",
    "    start = ee.Date.fromYMD(y,m,d).advance(-1, \"day\")\n",
    "    end = ee.Date.fromYMD(y,m,d)\n",
    "    prod = product.filterDate(start, end).sort('system:time_start', False).select(\"ppt\")\n",
    "    return prod\n",
    "\n",
    "def get_2day_precip(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.sum(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"ppt\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "def get_ndvi(latlon_obj, area):\n",
    "    res = latlon_obj.reduceRegion(reducer=ee.Reducer.mean(),geometry=area,scale=10)\n",
    "    data = np.array((ee.Array(res.get(\"NDVI\")).getInfo()))\n",
    "    out = np.array(data)\n",
    "    return out \n",
    "\n",
    "def round_up_to_odd(f):\n",
    "    f = int(np.ceil(f))\n",
    "    return f + 1 if f % 2 == 0 else f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_file = gp.read_file(\"../shape/scan_sites.shp\")\n",
    "sites = site_file[~site_file['state'].isin([\"AK\", \"HI\", \"PR\", \"VI\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rs.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processings site no 2057\n",
      "Deciduous Forest  - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species shed foliage simultaneously in response to seasonal change.\n",
      "no valid overpasses\n",
      "Processings site no 2078\n",
      "Cultivated Crops - Areas used for the production of annual crops, such as corn, soybeans, vegetables, tobacco, and cotton, and also perennial woody crops such as orchards and vineyards. Crop vegetation accounts for greater than 20 percent of total vegetation. This class also includes all land being actively tilled.\n",
      "no valid overpasses\n",
      "Processings site no 2177\n",
      "Cultivated Crops - Areas used for the production of annual crops, such as corn, soybeans, vegetables, tobacco, and cotton, and also perennial woody crops such as orchards and vineyards. Crop vegetation accounts for greater than 20 percent of total vegetation. This class also includes all land being actively tilled.\n",
      "no valid overpasses\n",
      "Processings site no 2113\n",
      "Open Water - All areas of open water, generally with less than 25% cover or vegetation or soil.\n",
      "no valid overpasses\n",
      "Processings site no 2174\n",
      "Cultivated Crops - Areas used for the production of annual crops, such as corn, soybeans, vegetables, tobacco, and cotton, and also perennial woody crops such as orchards and vineyards. Crop vegetation accounts for greater than 20 percent of total vegetation. This class also includes all land being actively tilled.\n",
      "no valid overpasses\n",
      "Processings site no 2055\n",
      "Evergreen Forest - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species maintain their leaves all year. Canopy is never without green foliage.\n",
      "no valid overpasses\n",
      "Processings site no 2173\n",
      "Pasture/Hay - Areas of grasses, legumes, or grass-legume mixtures planted for livestock grazing or the production of seed or hay crops, typically on a perennial cycle. Pasture/hay vegetation accounts for greater than 20 percent of total vegetation.\n",
      "no valid overpasses\n",
      "Processings site no 2180\n",
      "Developed, Open Space - Includes areas with a mixture of some constructed materials, but mostly vegetation in the form of lawn grasses.  Impervious surfaces account for less than 20 percent of total cover. These areas most commonly include large-lot single-family housing units, parks, golf courses, and vegetation planted in developed settings for recreation, erosion control, or aesthetic purposes.\n",
      "no valid overpasses\n",
      "Processings site no 2114\n",
      "Mixed Forest - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. Neither deciduous nor evergreen species are greater than 75 percent of total tree cover.\n",
      "no valid overpasses\n",
      "Processings site no 2178\n",
      "Developed, Open Space - Includes areas with a mixture of some constructed materials, but mostly vegetation in the form of lawn grasses.  Impervious surfaces account for less than 20 percent of total cover. These areas most commonly include large-lot single-family housing units, parks, golf courses, and vegetation planted in developed settings for recreation, erosion control, or aesthetic purposes.\n",
      "no valid overpasses\n",
      "Processings site no 2181\n",
      "Cultivated Crops - Areas used for the production of annual crops, such as corn, soybeans, vegetables, tobacco, and cotton, and also perennial woody crops such as orchards and vineyards. Crop vegetation accounts for greater than 20 percent of total vegetation. This class also includes all land being actively tilled.\n",
      "no valid overpasses\n",
      "Processings site no 2182\n",
      "Pasture/Hay - Areas of grasses, legumes, or grass-legume mixtures planted for livestock grazing or the production of seed or hay crops, typically on a perennial cycle. Pasture/hay vegetation accounts for greater than 20 percent of total vegetation.\n",
      "no valid overpasses\n",
      "Processings site no 2176\n",
      "Evergreen Forest - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species maintain their leaves all year. Canopy is never without green foliage.\n",
      "no valid overpasses\n",
      "Processings site no 2056\n",
      "Developed, Open Space - Includes areas with a mixture of some constructed materials, but mostly vegetation in the form of lawn grasses.  Impervious surfaces account for less than 20 percent of total cover. These areas most commonly include large-lot single-family housing units, parks, golf courses, and vegetation planted in developed settings for recreation, erosion control, or aesthetic purposes.\n",
      "no valid overpasses\n",
      "Processings site no 2179\n",
      "Deciduous Forest  - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species shed foliage simultaneously in response to seasonal change.\n",
      "no valid overpasses\n",
      "Processings site no 2115\n",
      "Pasture/Hay - Areas of grasses, legumes, or grass-legume mixtures planted for livestock grazing or the production of seed or hay crops, typically on a perennial cycle. Pasture/hay vegetation accounts for greater than 20 percent of total vegetation.\n",
      "no valid overpasses\n",
      "Processings site no 2175\n",
      "Deciduous Forest  - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species shed foliage simultaneously in response to seasonal change.\n"
     ]
    }
   ],
   "source": [
    "# For each site id, find the sm file with the data (in data dir), \n",
    "# calculate psi as psi = A * SM ^b (krishna's paper )\n",
    "# query the (1) landcover, (2) Sentinel backscatter (Prism P), MODIS / Landsat LAI for the whole timeseries \n",
    "   \n",
    "for idx, row in sites.iterrows():\n",
    "    \n",
    "    if row.id in out_dict.keys():\n",
    "        print(row.id)\n",
    "        continue\n",
    "        \n",
    "    print(\"Processings site no {}\".format(row.id))\n",
    "    \n",
    "    # Make geom to submit to EE \n",
    "    x,y = row.geometry.buffer(0.0001).envelope.exterior.coords.xy\n",
    "    coords = [list(zip(x,y))]\n",
    "    area = ee.Geometry.Polygon(coords)\n",
    "    \n",
    "    # Get the corresponding SCAN data file from data folder\n",
    "    site_id = row.id\n",
    "    sm_file = [os.path.join(data_dir,x) for x in os.listdir(data_dir) if site_id in x][0]\n",
    "    sm_dat = read_sm_file(sm_file)\n",
    "    sm_dat['Date'] =  pd.to_datetime(sm_dat['Date'], format='%Y%m%d %H:%M')\n",
    "    sm_dat.set_index('Date', inplace=True)\n",
    "        \n",
    "    # start and end date\n",
    "    if sm_dat.empty:\n",
    "        print(\"no valid soil moisture data for {}\".format(row.id))\n",
    "        continue\n",
    "        \n",
    "    startdate = sm_dat.index[0]\n",
    "    enddate = sm_dat.index[-1]\n",
    "    \n",
    "    date = startdate.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    # Select the nlcd dataset\n",
    "    dataset =  rs.load_data()['nlcd']\n",
    "    ic = dataset[0]\n",
    "    var = dataset[1]\n",
    "    res = dataset[3]\n",
    "    \n",
    "    # find the nearest nlcd dataset \n",
    "    col = ic.filterDate(ee.Date(date).advance(-1, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    if not col.getInfo():\n",
    "        col = ic.filterDate(ee.Date(date).advance(-3, 'years'), ee.Date(date).advance(2, 'years')).first()\n",
    "    t = col.reduceRegion(ee.Reducer.frequencyHistogram(), area, res).get(var)\n",
    "    meta = col.getInfo()\n",
    "    lc_class = int(list(t.getInfo().keys())[0])\n",
    "    \n",
    "    # Get the landcover type\n",
    "    lcidx = meta['properties']['landcover_class_values'].index(lc_class)\n",
    "    lctype = meta['properties']['landcover_class_names'][lcidx]\n",
    "    print(lctype)\n",
    "    \n",
    "    # Get Sentinel images and dates (ascending orbits only, VV polarization)\n",
    "    s1 = rs.load_data()['s1']\n",
    "    s1ic, s1var, s1res = s1[0], s1[1], s1[3]\n",
    "    s1var = \"HV\"\n",
    "    \n",
    "    s1_col = s1ic.filterBounds(area).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'HV'))\n",
    "    s1_col = s1_col.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).select(s1var)\n",
    "    \n",
    "    # Krishna used ascending pass... I think descending is the correct orbit for the AM \n",
    "    \n",
    "    s1_col = s1_col.filterDate(startdate,enddate)\n",
    "    t = s1_col.sort('system:time_start')\n",
    "    \n",
    "    try:\n",
    "        ims = t.toList(t.size())\n",
    "        print(\"Processing {} sentinel overapasses\".format(len(ims.getInfo())))\n",
    "        s1dat, dates = get_ims_by_date(ims,s1var)\n",
    "        \n",
    "    except:\n",
    "        print(\"no valid overpasses\")\n",
    "        continue\n",
    "    \n",
    "    # Calc the S1 backscatter in each image\n",
    "    mean_sigmas = []\n",
    "    std_sigmas = []\n",
    "\n",
    "    for i in s1dat:\n",
    "        mean_sigmas.append(np.mean(i))\n",
    "        std_sigmas.append(np.std(i))\n",
    "        \n",
    "    # Convert the datestrings from S1 to pandas datetimes \n",
    "    for idx, x in enumerate(dates):\n",
    "        timestamp = x.find(\"V_\")+2\n",
    "        timestr = x[timestamp:timestamp+13]\n",
    "        dates[idx] = pd.to_datetime(timestr, format='%Y%m%d %H:%M')\n",
    "        \n",
    "    # Get PRISM data for all the S1 overpass dates to filter the rainy days\n",
    "    print(\"processing PRISM\")\n",
    "    rainfall = []\n",
    "\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "        \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "        t = filter_date(rs.load_data()['prism_daily'][0], y, m, d).sum()\n",
    "        precip_total = get_2day_precip(t, area)\n",
    "        rainfall.append(precip_total)\n",
    "\n",
    "    \n",
    "    # MODIS LAI \n",
    "    print(\"processing MODIS\")\n",
    "    modis = rs.load_data()['modis_lai']\n",
    "    mic, mvar, mres = modis[0],modis[1], modis[2]\n",
    "\n",
    "    modis_lai = []\n",
    "    for i,x in enumerate(dates):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / len(dates))*100)[:5] + \" % \")\n",
    "            \n",
    "        y,m,d = dates[i].year, dates[i].month, dates[i].day\n",
    "\n",
    "        start = ee.Date.fromYMD(y,m,d).advance(-2,\"day\")\n",
    "        end = ee.Date.fromYMD(y,m,d).advance(2, \"day\")\n",
    "\n",
    "        prod = mic.filterDate(start, end).sort('system:time_start', False).select(mvar).first()\n",
    "\n",
    "        try:\n",
    "            res = prod.reduceRegion(reducer=ee.Reducer.first(),geometry=area,scale=5) # Need to have scale smaller than geom\n",
    "            data = np.array((ee.Array(res.get(mvar)).getInfo()))\n",
    "            out = np.array(data)* 0.1\n",
    "            modis_lai.append(out)\n",
    "        except:\n",
    "            out = np.nan\n",
    "            modis_lai.append(np.nan)\n",
    "            \n",
    "    # Landsat - Note: some sites are in the overlap areas between passes.\n",
    "    # these sites can have multiple obs / day or obs separated by 8days instead of 16. \n",
    "    \n",
    "    print(\"Processing Landsat\")\n",
    "    landsat = rs.load_data()['l8_sr']\n",
    "    lic, lvar, lsf = landsat[0],landsat[1], landsat[2]\n",
    "\n",
    "    lstart = ee.Date.fromYMD(startdate.year,startdate.month,startdate.day).advance(-16,\"day\")\n",
    "    lend = ee.Date.fromYMD(enddate.year,enddate.month,enddate.day).advance(16, \"day\")\n",
    "\n",
    "    l8_col = lic.filterDate(lstart,lend).filterBounds(area).map(rs.mask_quality) # Mask clouds and shadows \n",
    "    lt = l8_col.sort('system:time_start')\n",
    "    lims = lt.toList(lt.size())\n",
    "\n",
    "    num_ims = len(lims.getInfo())\n",
    "\n",
    "    ldfs = []\n",
    "\n",
    "    for i in range (0, num_ims):\n",
    "        if i % 5 == 0:\n",
    "            print(str((i / num_ims)*100)[:5] + \" % \")\n",
    "\n",
    "        ls_latlon = ee.Image.pixelLonLat().addBands(lims.get(i))\n",
    "        ltemp = ls_latlon.select([\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\"]).multiply(lsf)\n",
    "        l8_res = ltemp.reduceRegion(reducer=ee.Reducer.mean(),geometry=area,bestEffort=True,scale=30)\n",
    "\n",
    "        l8_info_dict = lims.get(i).getInfo()\n",
    "        l8_date = l8_info_dict['id'][-8:]\n",
    "\n",
    "        l8_out = l8_res.getInfo()\n",
    "\n",
    "        ldf = pd.DataFrame.from_dict(l8_out.values()).T\n",
    "        ldf.columns = l8_out.keys()\n",
    "        ldf.index = pd.to_datetime([l8_date])\n",
    "        ldfs.append(ldf)\n",
    "        \n",
    "                        \n",
    "    # Filter the SCAN data for the S1 dates, 3 am - 7 am \n",
    "    rzsm = []\n",
    "    ssm = []\n",
    "    \n",
    "    for i in dates:\n",
    "        starttime = i.replace(second=0, microsecond=0, minute=0, hour=3)\n",
    "        endtime = starttime+timedelta(hours= 4)\n",
    "        df = pd.DataFrame(sm_dat[starttime:endtime])\n",
    "        \n",
    "        rzsm.append(df[df.columns[-1]].values)\n",
    "        ssm.append(df[df.columns[-3]].values)\n",
    "    \n",
    "    # In case there are nans or data gaps in the sm data\n",
    "    rzsm = [list(filter(None, x)) for x in rzsm]\n",
    "    ssm = [list(filter(None, x)) for x in ssm]\n",
    "    \n",
    "    # Calc the 5 hour mean for each sensor reading \n",
    "    for idx,x in enumerate(rzsm):\n",
    "        rzsm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "    \n",
    "    for idx,x in enumerate(ssm):\n",
    "        ssm[idx] = np.nanmean([np.float(i) for i in x])\n",
    "\n",
    "    # params to calculate psi \n",
    "    a = row.a\n",
    "    b = row.b\n",
    "    \n",
    "    # RZ and Surface LWP = A * sm ^b\n",
    "    psi1 = [a*(x/100)**b for x in rzsm]\n",
    "    psi2 = [a*(x/100)**b for x in ssm]\n",
    "    \n",
    "    # Make a dataframe out of everything\n",
    "    df = pd.DataFrame([dates, mean_sigmas, std_sigmas, rainfall, modis_lai, rzsm,psi1,ssm,psi2, [lcidx]*len(dates)])\n",
    "    df = df.T\n",
    "    df.columns = (['date', \"sigma\", \"std_sigma\", \"precip\",\"LAI\", \"rzsm\",\"psi_rz\", \"ssm\", \"psi_s\", \"lc_type\"])\n",
    "    df = rs.col_to_dt(df) # set the date col as datetime index \n",
    "    mask=(df['precip'] < 0.1)\n",
    "    dfout = df[mask]\n",
    "\n",
    "    # Golay interpolation for landsat \n",
    "    \n",
    "    ls = pd.concat(ldfs)\n",
    "    win_len = round_up_to_odd(num_ims/7)\n",
    "    \n",
    "    for i in ls.columns:\n",
    "        ls[i][ls[i] == 0] = np.nan\n",
    "        ls[i] = ls[i].interpolate(method = \"linear\")\n",
    "        ls[i+\"_filt\"] = savgol_filter(ls[i], window_length=win_len, polyorder=2)\n",
    "    \n",
    "    ls_df = ls[(ls.T != 0).any()]\n",
    "    ls_df = ls_df.groupby(level = 0).mean()\n",
    "    \n",
    "    # Break the loop if there are no non- rainy sentinel overpasses \n",
    "    if dfout.empty:\n",
    "        print(\"No non-rainy overpaasses \")\n",
    "        continue \n",
    "        \n",
    "    l8_dfs = []\n",
    "    \n",
    "    for i in dfout.index:\n",
    "        l8_idx = ls_df.index.get_loc(i, method='nearest')\n",
    "        l8_contemp = ls_df.iloc[l8_idx]\n",
    "        t = pd.DataFrame(l8_contemp).T\n",
    "        l8_dfs.append(t)\n",
    "    \n",
    "    fin_ls = pd.concat(l8_dfs)\n",
    "\n",
    "    FIN = pd.concat( [dfout.reset_index(drop=True), fin_ls.reset_index(drop=True)], axis=1) \n",
    "    FIN.index = dfout.index\n",
    "\n",
    "    print(FIN.head())\n",
    "    \n",
    "    out_dict[(row.id)] = FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat(out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7684"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_csv(\"../data/all_dat_desc.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
